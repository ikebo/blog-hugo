<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Ike&#39;Log</title>
    <link>https://ikebo.cc/post/</link>
    <description>Recent content in Posts on Ike&#39;Log</description>
    <image>
      <title>Ike&#39;Log</title>
      <url>https://ikebo.cc/papermod-cover.png</url>
      <link>https://ikebo.cc/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 24 Jun 2024 10:58:39 +0800</lastBuildDate><atom:link href="https://ikebo.cc/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://ikebo.cc/post/2024/06/-/</link>
      <pubDate>Mon, 24 Jun 2024 10:58:39 +0800</pubDate>
      
      <guid>https://ikebo.cc/post/2024/06/-/</guid>
      <description></description>
    </item>
    
    <item>
      <title>如何成就一番事业</title>
      <link>https://ikebo.cc/post/2024/06/%E5%A6%82%E4%BD%95%E6%88%90%E5%B0%B1%E4%B8%80%E7%95%AA%E4%BA%8B%E4%B8%9A/</link>
      <pubDate>Mon, 03 Jun 2024 14:30:39 +0800</pubDate>
      
      <guid>https://ikebo.cc/post/2024/06/%E5%A6%82%E4%BD%95%E6%88%90%E5%B0%B1%E4%B8%80%E7%95%AA%E4%BA%8B%E4%B8%9A/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Nginx Proxy Manager 单机多Docker Compose 反向代理配置</title>
      <link>https://ikebo.cc/post/2024/05/nginx-proxy-manager-%E5%8D%95%E6%9C%BA%E5%A4%9Adocker-compose-%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Tue, 21 May 2024 19:17:55 +0800</pubDate>
      
      <guid>https://ikebo.cc/post/2024/05/nginx-proxy-manager-%E5%8D%95%E6%9C%BA%E5%A4%9Adocker-compose-%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/</guid>
      <description>问题描述 单机下部署多个docker-compose, 并用nginx proxy manager 反代其他docker compose的流量，出现连不上其他docker compose 下的container的问题
尝试过的解决方式 1、地址用docker0的地址，端口用其他container暴露出来的端口，不行 2、换机器，不行 3、换docker、docker-compose 版本，不行
最终的解决方式 手动将多个docker compose加入到同一个docker network.
具体参考: 1、https://nginxproxymanager.com/advanced-config 2、https://stackoverflow.com/questions/38088279/communication-between-multiple-docker-compose-projects 3、https://github.com/NginxProxyManager/nginx-proxy-manager/issues/555
05.20 更新 最终还是要解决容器内无法访问宿主机IP的问题，非常诡异： 1、容器内可以ping通其他容器的hostname, 端口也是通的 2、容器内可以ping通宿主机ip (eth0) 3、但是容器无法连上宿主机的端口 4、公网可以正常访问宿主机的服务(端口是通的)
排查一圈发现是防火墙的原因，Ubuntu 22.04 TLS, 记得要把防火墙关了！(ufw disable)
艹！
参考过的几个有用文章： 1、https://juejin.cn/post/7180619106407120933 2、https://gist.github.com/bruno-brant/e119da3713a657036ff7e3446d98176a
一般软件打的镜像都比较轻量，用的alpine版的linux比较多，进容器后用apk update &amp;amp;&amp;amp; apk add&amp;hellip; 装一些常用软件，方便排查问题。</description>
    </item>
    
    <item>
      <title>MySQL InnoDB 行记录格式(ROW_FORMAT)</title>
      <link>https://ikebo.cc/post/2024/04/mysql-innodb-%E8%A1%8C%E8%AE%B0%E5%BD%95%E6%A0%BC%E5%BC%8Frow_format/</link>
      <pubDate>Tue, 30 Apr 2024 11:48:10 +0800</pubDate>
      
      <guid>https://ikebo.cc/post/2024/04/mysql-innodb-%E8%A1%8C%E8%AE%B0%E5%BD%95%E6%A0%BC%E5%BC%8Frow_format/</guid>
      <description>MySQL InnoDB 行记录格式（ROW_FORMAT）
一、行记录格式的分类和介绍
在早期的InnoDB版本中，由于文件格式只有一种，因此不需要为此文件格式命名。随着InnoDB引擎的发展，开发出了不兼容早期版本的新文件格式，用于支持新的功能。为了在升级和降级情况下帮助管理系统的兼容性，以及运行不同的MySQL版本，InnoDB开始使用命名的文件格式。
1. Antelope: 先前未命名的，原始的InnoDB文件格式。它支持两种行格式：COMPACT 和 REDUNDANT。MySQL5.6的默认文件格式。可以与早期的版本保持最大的兼容性。不支持 Barracuda 文件格式。
2. Barracuda: 新的文件格式。它支持InnoDB的所有行格式，包括新的行格式：COMPRESSED 和 DYNAMIC。与这两个新的行格式相关的功能包括：InnoDB表的压缩，长列数据的页外存储和索引建前缀最大长度为3072字节。
在 msyql 5.7.9 及以后版本，默认行格式由innodb_default_row_format变量决定，它的默认值是DYNAMIC，也可以在 create table 的时候指定ROW_FORMAT=DYNAMIC。用户可以通过命令 SHOW TABLE STATUS LIKE&#39;table_name&#39; 来查看当前表使用的行格式，其中 row_format 列表示当前所使用的行记录结构类型。
PS：如果要修改现有表的行模式为compressed或dynamic，必须先将文件格式设置成Barracuda：set global innodb_file_format=Barracuda;，再用ALTER TABLE tablename ROW_FORMAT=COMPRESSED;去修改才能生效。
mysql&amp;gt; show variables like &amp;#34;innodb_file_format&amp;#34;; +--------------------+-----------+ | Variable_name | Value | +--------------------+-----------+ | innodb_file_format | Barracuda | +--------------------+-----------+ 1 row in set (0.00 sec) mysql&amp;gt; show table status like &amp;#34;test%&amp;#34;\G *************************** 1. row *************************** Name: test Engine: MyISAM Version: 10 Row_format: Dynamic Rows: 4 Avg_row_length: 20 Data_length: 80 Max_data_length: 281474976710655 Index_length: 1024 Data_free: 0 Auto_increment: NULL Create_time: 2018-08-07 13:07:59 Update_time: 2018-08-07 13:08:01 Check_time: NULL Collation: utf8_general_ci Checksum: NULL Create_options: row_format=DYNAMIC Comment: 二、InnoDB行存储</description>
    </item>
    
    <item>
      <title>Understanding Character Sets and Collations in MySQL</title>
      <link>https://ikebo.cc/post/2024/04/understanding-character-sets-and-collations-in-mysql/</link>
      <pubDate>Tue, 30 Apr 2024 11:27:57 +0800</pubDate>
      
      <guid>https://ikebo.cc/post/2024/04/understanding-character-sets-and-collations-in-mysql/</guid>
      <description>If you have ever worked with MySQL, you inevitably came across character sets and collations. In this blog post, we will try to give you a more in-depth look at what those two are and how you should use them.
What Are Character Sets and Collations? Simply put, character sets in MySQL are sets of symbols and encodings &amp;ndash; collations are sets of rules for comparing characters in a character set.</description>
    </item>
    
    <item>
      <title>架构设计和概要设计</title>
      <link>https://ikebo.cc/post/2024/04/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E6%A6%82%E8%A6%81%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Tue, 09 Apr 2024 16:14:20 +0800</pubDate>
      
      <guid>https://ikebo.cc/post/2024/04/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E6%A6%82%E8%A6%81%E8%AE%BE%E8%AE%A1/</guid>
      <description>初步再来探讨下架构设计和概要设计的区别和边界问题。先谈下架构设计：
架构设计包括了功能性架构和技术架构设计两个部分的内容，功能性架构解决业务流程和功能问题，而技术架构解决非功能性需求等问题。两种架构都包括了动态和静态两个方面的内容，对于功能性架构中动态部分为业务流程驱动全局用例，用例驱动的用例实现等；对于技术架构中动态部分为架构运行机制，而静态部分为框架，分层等方面的内容。
功能性架构包括了全局用例设计，这个本身是用例分析和设计的一个延续，而全局用例分析建议的思路仍然是业务流程，业务用例建模到系统用例建模的过程。全局用例分析清楚后可以开始考虑子系统和模块的划分，形成系统的功能架构图，当然在划分过程中一定要考虑到通过CRUD矩阵等分析方法来分析模块如何划分合理，如何保证模块本身高内聚和松耦合。
在全局用例分析完成后涉及到数据模型的设计，数据建模仍然从业务驱动，从最初的业务对象和单据入手，到最终的数据概念模型和逻辑模型等。架构设计中全局数据模型不一定覆盖所有的数据对象和数据表；但是核心的主数据，核心业务单据数据一定要覆盖到，模型到的层次到逻辑模型即可。如果用面向对象的分析方法，这里需要出的是UML建模中的概念模型和逻辑模型，体现核心对象和类，核心对象和类之间的关系。
将全局用例分析和数据模型建立融合在一起，可以看到这两者结合起来会形成一个系统完成的领域模型层。一直认为领域模型思路应该引入架构设计，只有领域模型才是真正关注功能性架构，而不用马上关注到具体的技术分层和技术实现。
前面两者做完后可以看到一个大系统被分解为了多个子系统或模块，那么接着要考虑的就是模块间的集成架构，分析完集成架构模块间的接口基本就出来了。接口设计应该是架构设计的另外一个核心内容。要明白架构设计一个重要作用就是架构设计完成后各个模块可以并行开始概要设计，详细设计和开发工作。只要大家都遵循架构设计约定的接口规则即可以了。
集成架构考虑完另外一个核心内容就是公共可复用组件的抽取和识别，包括了功能组件和技术组件，需要识别出来哪些是可复用的，如何进行复用。对于复用层次本身又包括了数据层复用，逻辑层组件复用，界面层UI组件的复用等。复用是架构价值体现的的另外一个关键点。
这些都做完后，接着一个步骤应该在架构设计阶段做的就是对架构输出成功进行模拟验证，前面完成了分解动作，必须通过模拟验证来看看后续分解内容能否很好的集成和组装。很多时候我们做架构设计的时候往往不做这块内容，导致架构设计一些内容变成空中楼阁，无法落地。
再回来看技术架构设计，首先谈下静态部分的内容。这里面就包括了软件开发的分层架构，开发框架等内容，包括开发规范约定，技术平台和语言的选择，使用的规约等都需要考虑。很多时候我们看到谈架构的时候说到的三层或多层架构，仅仅是完整架构设计里面很小的一部分内容。
除了分层架构外，接着考虑的就是各种非功能性需要，我们在架构上需要如何设计。这里面包括了事务，缓存，异常，日志，安全，性能，可用性，容错能力等。这些逐个点都要在架构设计中说清楚如何考虑，由于这些本身就属于一个应用系统中技术平台要考虑的内容，因此应该设计为较为公用的技术组件供上层的业务组件使用。要明白很多时候为何谈到AOP或可插拔架构，只有这样去考虑问题，才会考虑真正的功能性架构设计和功能实现和非功能性技术架构这块充分解耦，实现进一步的灵活装配。
再回到架构设计视图层面，还需要考虑的就是整个应用系统的部署架构，部署架构本身也包括了逻辑视图和物理视图，应用最终开发出来了如何进行部署，这涉及到了IT基础架构方面的细化，也需要考虑清楚。
概要设计
概要设计首先要明白的是根据架构设计的内容进一步对某个模块的设计进一步细化。架构设计在系统级，而概要设计在子系统或模块级。拿建筑来比喻，架构设计是把一个建筑的框架结构全部定清楚，包括地基要挖多深，核心框架和承重结构如何，每一层的结构图如何，应该分为几个大套间这些内容都应该定下来。每个大套间的水，电，气等管道接入点在哪里等。而概要设计要做的是拿着一个套间，来考虑这个套间内部该如何设计，如何划分功能区域，如何将水电气接入点进一步在房间内延伸，哪些地方需要进一步增加非承重的隔断等。
基于以上思路我们看到在架构设计的时候，除了很少部分的核心用例我们会谈到具体的用例实现完，大多数功能我们都不会谈到具体的用例实现层面。而到了概要设计则需要进一步的分解我这块模块究竟需要实现哪些功能点，具体的每个功能点究竟如何实现都必须要考虑到。
严格的概要设计，我们希望是到了概要设计的某个功能模块，模块所涉及到的核心的类全部会出来，类关系图全部会出来。数据库设计也进一步细化到该模块的数据库物理模型。对于用例进行用例实现分析，在实现分析过程中可以看到每个类核心的public方法全部会分析识别出来。
拿着架构设计的接口，概要设计也需要进一步细化，细化出接口具体的输入输出和使用方法，包括模块应该使用哪些外部接口，模块本身又提供哪些接口出去都必须细化清楚。做概要设计的时候一定要清楚当前做的这个模块在整个应用系统架构中的位置，和外部的集成和交互点。
概要设计不用到详细设计这么细化，包括类里面的私有方法，public方法的具体实现步骤和逻辑，伪代码等。但是我们要看到概要设计里面对于核心的业务逻辑必须要设计清楚如何实现，实现的机制和方法。很多时候我们到了概要设计画uml的时序图，很多时候一看没有任何意义，全是跨层的简单的交互和调用。这个应该在架构设计的架构运行机制说清楚即可。设计到多个业务类间的交互调用才是重点，一个简单的功能增删改查，完全没有必要画什么时序图。
其次架构设计中给出了各种安全，性能，缓存的设计。那么在概要设计中出来另外一个问题，即架构给出的各种实现方案和技术，我们在概要设计中如何选择，如何使用。不是所有功能都需要缓存，那就要说清楚哪些功能根据分析需要缓存，需要缓存哪些对象，缓存本身的时效性如何设置等问题。
概要设计作为我们要达到一个目的，就是不论是谁拿走概要设计来做，最终实现出来的功能模块不会走样，功能模块最终实现出来可能有性能，易用性等方面的问题，但是整个功能实现的大框架一定是定了的。
另外一篇文章可参考：http://321echo.blog.163.com/blog/static/999257872010020102113705/
转载自博客园</description>
    </item>
    
    <item>
      <title>ARTS打卡 第四周</title>
      <link>https://ikebo.cc/post/arts%E6%89%93%E5%8D%A1-%E7%AC%AC%E5%9B%9B%E5%91%A8/</link>
      <pubDate>Mon, 11 Sep 2023 21:02:17 +0800</pubDate>
      
      <guid>https://ikebo.cc/post/arts%E6%89%93%E5%8D%A1-%E7%AC%AC%E5%9B%9B%E5%91%A8/</guid>
      <description>1、Algorithm 无重复字符的最长子串 给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度。
示例 1: 输入: s = &amp;ldquo;abcabcbb&amp;rdquo; 输出: 3 解释: 因为无重复字符的最长子串是 &amp;ldquo;abc&amp;rdquo;，所以其长度为 3。
示例 2: 输入: s = &amp;ldquo;bbbbb&amp;rdquo; 输出: 1 解释: 因为无重复字符的最长子串是 &amp;ldquo;b&amp;rdquo;，所以其长度为 1。
示例 3: 输入: s = &amp;ldquo;pwwkew&amp;rdquo; 输出: 3 解释: 因为无重复字符的最长子串是 &amp;ldquo;wke&amp;rdquo;，所以其长度为 3。 请注意，你的答案必须是 子串 的长度，&amp;ldquo;pwke&amp;rdquo; 是一个子序列，不是子串。
提示： 0 &amp;lt;= s.length &amp;lt;= 5 * 104 s 由英文字母、数字、符号和空格组成 思路 这道题主要用到思路是：滑动窗口
什么是滑动窗口？
其实就是一个队列,比如例题中的 abcabcbb，进入这个队列（窗口）为 abc 满足题目要求，当再进入 a，队列变成了 abca，这时候不满足要求。所以，我们要移动这个队列！
如何移动？
我们只要把队列的左边的元素移出就行了，直到满足题目要求！
一直维持这样的队列，找出队列出现最长的长度时候，求出解！
时间复杂度：O(n)</description>
    </item>
    
    <item>
      <title>ARTS打卡 - 第三周</title>
      <link>https://ikebo.cc/post/arts%E6%89%93%E5%8D%A1-%E7%AC%AC%E4%B8%89%E5%91%A8/</link>
      <pubDate>Mon, 04 Sep 2023 20:47:59 +0800</pubDate>
      
      <guid>https://ikebo.cc/post/arts%E6%89%93%E5%8D%A1-%E7%AC%AC%E4%B8%89%E5%91%A8/</guid>
      <description>1、Algorithm 和为 K 的子数组 给你一个整数数组 nums 和一个整数 k ，请你统计并返回 该数组中和为 k 的连续子数组的个数 。
示例 1： 输入：nums = [1,1,1], k = 2 输出：2
示例 2： 输入：nums = [1,2,3], k = 3 输出：2
提示： 1 &amp;lt;= nums.length &amp;lt;= 2 * 104 -1000 &amp;lt;= nums[i] &amp;lt;= 1000 -107 &amp;lt;= k &amp;lt;= 107 思路 我们可以基于方法一利用数据结构进行进一步的优化，我们知道方法一的瓶颈在于对每个 iii，我们需要枚举所有的 jjj 来判断是否符合条件，这一步是否可以优化呢？答案是可以的。
我们定义 pre[i]为[0..i]里所有数的和，则 pre[i]可以由 pre[i−1]递推而来，即：
pre[i]=pre[i−1]+nums[i]
那么[j..i]这个子数组和为k这个条件我们可以转化为
pre[i]−pre[j−1]==k
简单移项可得符合条件的下标j需要满足:
pre[j−1]==pre[i]−k
所以我们考虑以i结尾的和为k的连续子数组个数时只要统计有多少个前缀和为pre[i]−k的pre[j]即可。
代码 public class Solution { public int subarraySum(int[] nums, int k) { int count = 0, pre = 0; HashMap &amp;lt; Integer, Integer &amp;gt; mp = new HashMap &amp;lt; &amp;gt; (); mp.</description>
    </item>
    
    <item>
      <title>ARTS打卡 - 第二周</title>
      <link>https://ikebo.cc/post/arts-2/</link>
      <pubDate>Mon, 28 Aug 2023 23:58:50 +0800</pubDate>
      
      <guid>https://ikebo.cc/post/arts-2/</guid>
      <description>1、Algorithm 换水问题 超市正在促销，你可以用 numExchange 个空水瓶从超市兑换一瓶水。最开始，你一共购入了 numBottles 瓶水。
如果喝掉了水瓶中的水，那么水瓶就会变成空的。
给你两个整数 numBottles 和 numExchange ，返回你 最多 可以喝到多少瓶水。
示例 示例 1： 输入：numBottles = 9, numExchange = 3 输出：13 解释：你可以用 3 个空瓶兑换 1 瓶水。 所以最多能喝到 9 + 3 + 1 = 13 瓶水。
示例2 输入：numBottles = 15, numExchange = 4 输出：19 解释：你可以用 4 个空瓶兑换 1 瓶水。 所以最多能喝到 15 + 3 + 1 = 19 瓶水。
提示：
1 &amp;lt;= numBottles &amp;lt;= 100 2 &amp;lt;= numExchange &amp;lt;= 100 思路 首先我们一定可以喝到 bbb 瓶酒，剩下 bbb 个空瓶。接下来我们可以拿瓶子换酒，每次拿出 eee 个瓶子换一瓶酒，然后再喝完这瓶酒，得到一个空瓶。以此类推，我们可以统计得到答案。</description>
    </item>
    
    <item>
      <title>ARTS打卡 - 第一周</title>
      <link>https://ikebo.cc/post/arts%E6%89%93%E5%8D%A1-%E7%AC%AC%E4%B8%80%E5%91%A8/</link>
      <pubDate>Mon, 21 Aug 2023 22:27:21 +0800</pubDate>
      
      <guid>https://ikebo.cc/post/arts%E6%89%93%E5%8D%A1-%E7%AC%AC%E4%B8%80%E5%91%A8/</guid>
      <description>前言 我不是一个喜欢凑热闹的人, 越是热闹的东西，我越是不碰，似乎要与全世界作对，我不玩抖音、不玩微博等乱七八糟的东西，那铺面而来的信息令我惶恐不安。
但是这次不一样，陈皓老师在我前进的道路上给了我精神上很大的鼓舞，我还记得大约三年前，刚转正正式参加工作的时候，看着陈皓博客的文章，让我热血沸腾的感觉，心想有一天我也要成为这么牛逼的程序员。虽然我现在还远远没有达到，但是这种信念似乎还一直在我心中，这个更加重要。
多说几句吧
刚开始工作第一年，业余时间基本都在按照陈皓老师的专栏中介绍的路径在补充学习，汇编，unp，apue等，虽然现在几乎全忘光了，但是我怀念那种感觉。
陈皓老师去世了，世事无常阿卧槽！
1、Algorithm 颜色分类(荷兰国旗问题) 给定一个包含红色、白色和蓝色，一共 n 个元素的数组，原地对它们进行排序，使得相同颜色的元素相邻，并按照红色、白色、蓝色顺序排列。
此题中，我们使用整数 0、 1 和 2 分别表示红色、白色和蓝色。
注意: 不能使用代码库中的排序函数来解决这道题。
进阶： 一个直观的解决方案是使用计数排序的两趟扫描算法。 首先，迭代计算出0、1 和 2 元素的个数，然后按照0、1、2的排序，重写当前数组。 你能想出一个仅使用常数空间的一趟扫描算法吗？
示例 输入: [2,0,2,1,1,0] 输出: [0,0,1,1,2,2] 思路 双指针, 开始位置分别位于数组两端, 分别分割0和2的区域, 从左向右遍历，将0交换到左边, 将2交换到右边，然后处理一下终止和边界情况。
代码 class Solution: def sortcolors(self, nums: List[int]) -&amp;gt; None: n = len(nums) p0, p2 = 0, n - 1 i = 0 while i &amp;lt;= p2: while i &amp;lt;= p2 and nums[i] == 2: nums[i], nums[p2] = nums[p2], nums[i] p2 -= 1 if nums[i] == 0: nums[i], nums[p0] = nums[p0], nums[i] p0 += 1 i += 1 2、Review 分享一下medium中一篇关于规则引擎介绍的文章</description>
    </item>
    
    <item>
      <title>tg交易规范</title>
      <link>https://ikebo.cc/post/tg%E4%BA%A4%E6%98%93%E8%A7%84%E8%8C%83/</link>
      <pubDate>Sat, 15 Jul 2023 23:12:28 +0800</pubDate>
      
      <guid>https://ikebo.cc/post/tg%E4%BA%A4%E6%98%93%E8%A7%84%E8%8C%83/</guid>
      <description>tg交易规范 判断一个对象是否能与之进行交易：
1，如果对方有公开群聊、频道，且人数有一定规模，且是tg会员，可信度则相对较高
2，如果对方小白一个，群聊、频道啥都没有，而且是小白一个，可信度极低
不管是可信度较高还是极低，都要：
1，最大化对方跑路的成本
先服务 群聊公开实时交易信息 非全款 2，最小化对方跑路后我的损失
非全款 （每次只占小部分金额150以内） 先服务 以上原则一定要遵守，交易前建议看下这篇文章</description>
    </item>
    
    <item>
      <title>从tg交易中学习到的人性</title>
      <link>https://ikebo.cc/post/%E4%BB%8Etg%E4%BA%A4%E6%98%93%E4%B8%AD%E5%AD%A6%E4%B9%A0%E5%88%B0%E7%9A%84%E4%BA%BA%E6%80%A7/</link>
      <pubDate>Sat, 15 Jul 2023 23:12:15 +0800</pubDate>
      
      <guid>https://ikebo.cc/post/%E4%BB%8Etg%E4%BA%A4%E6%98%93%E4%B8%AD%E5%AD%A6%E4%B9%A0%E5%88%B0%E7%9A%84%E4%BA%BA%E6%80%A7/</guid>
      <description>从tg交易中感受到的人性 不要去考验人性
不要去考验人性
不要去考验人性
让双方在交易时，都能感受到，如果跑路，是有代价的，且这个代价不小于或者不明显大于不跑路的收益。
今天的例子，对方是个送外卖的，一天也就挣个100来块钱，你一次给他300，对方跑路没有任何损失，相反会得到3天的工资！换成我，我也会跑。
如果一次给90，充完，继续90，充完，继续90，然后给个50手续费，那结果大概率就不一样。
所以，付款前，站在对方的角度仔细想想，如果是你，你会跑路吗？90和50的区别不大的，或者一次充40，完事后给50！这样更OK.
这样的话，对方操作起来也比较顺畅，不会犹豫，因为他的人性没有受到考验。
这是我学到的很深刻的一课。
不要去考验人性，要避开人性的弱点。单纯靠人与人之前虚无的感情是不可靠的。
这次被骗，我也有责任，我做的不够周全，我思考的不够深刻，我对人性不够了解。</description>
    </item>
    
    <item>
      <title>博客再再开张</title>
      <link>https://ikebo.cc/post/%E5%8D%9A%E5%AE%A2%E5%86%8D%E5%86%8D%E5%BC%80%E5%BC%A0/</link>
      <pubDate>Sat, 15 Jul 2023 00:35:20 +0800</pubDate>
      
      <guid>https://ikebo.cc/post/%E5%8D%9A%E5%AE%A2%E5%86%8D%E5%86%8D%E5%BC%80%E5%BC%A0/</guid>
      <description>大概在两年前，我写了一篇《博客再开张》的文章，记录了我的博客迁移之旅。
最近，我的博客再次迁移。
迁移到了github，使用hugo + papermod 强力驱动☺️
为什么要迁移 说到底，就是维护成本
之前的维护成本为什么高 1，服务器
需要自己购买服务器，自运维，运维对象包括服务器续费，web服务维护(运行在docker中)
2，数据
博客数据需要定期备份, 写脚本定时dump下来，推送到github中存储起来
3，备案
之前有个备案站点，每年需要重新审核一次，而且我不太喜欢备案，现在已将备案信息删除，域名和服务器不再具有备案信息。
4，证书
免费证书每3个月需要维护一次，自动续期的话需要单独跑个进程。使用cloudflare服务的话，国内响应速度太慢。
所以，维护成本相对还是比较高的，加上平时业余时间不是很多，时间长了人就乏了，迫切需要维护成本低的博客方案。
为什么要写博客 有一天，我看到了别人的博客，看到他们写的文字，记录自己的想记录的东西。
我知道，那是我一直想做的事情，我必须继续做下去。
不写博客，当我回过头来，我会失落，会后悔，就这么感性的原因。
博客能记录自己文字，让自己的思绪有个干净的地方停留，以后能够回顾自己的心路历程。如果能给别人带来一些思考或者帮助，那也是极好的。
迁移之后维护成本为什么低 1，serverless
都是静态文件，no backend, no fucking logic.
2, continus deploy
I just need write a fucking markdown and git push.
为什么一开始没有使用这个方案 一开始是在CSDN上写，写了110多篇，记录自己日常学习时候的小收获，包括刷的算法题，解决过的case等，那是最初纯粹的初衷。 然后，想自己徒手写博客，锻炼自己的工程能力，项目经验等，于是自己徒手撸了一个简单博客，前后端都自己写。
然后，感觉功能比较弱，想要一个类似wordpress的博客，于是选了typecho建立博客
然后，i have no much time. 想简单点，just write something. 但是又不想用CSDN这样的平台，因为感觉平台不纯粹， 我自己写的东西，被平台免费拿走去赚广告费，还因为用了他们免费的博客服务沾沾自喜，no.
于是到了现在这一步，serverless，纯静态站.
后续计划 1，博客迁移，将之前写的博客迁移到这个站点（不包括CSDN） 2，完善站点功能，评论，站点统计，可能还会加个adsence😋
朋友，你也开始写博客吧，You need it.</description>
    </item>
    
    <item>
      <title>Hello World</title>
      <link>https://ikebo.cc/post/hello-world/</link>
      <pubDate>Sun, 09 Jul 2023 17:44:27 +0800</pubDate>
      
      <guid>https://ikebo.cc/post/hello-world/</guid>
      <description>Hello World </description>
    </item>
    
    <item>
      <title>汉字在屏幕上的显示过程以及乱码的原因</title>
      <link>https://ikebo.cc/post/migrate/part2/%E6%B1%89%E5%AD%97%E5%9C%A8%E5%B1%8F%E5%B9%95%E4%B8%8A%E7%9A%84%E6%98%BE%E7%A4%BA%E8%BF%87%E7%A8%8B%E4%BB%A5%E5%8F%8A%E4%B9%B1%E7%A0%81%E7%9A%84%E5%8E%9F%E5%9B%A0/</link>
      <pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E6%B1%89%E5%AD%97%E5%9C%A8%E5%B1%8F%E5%B9%95%E4%B8%8A%E7%9A%84%E6%98%BE%E7%A4%BA%E8%BF%87%E7%A8%8B%E4%BB%A5%E5%8F%8A%E4%B9%B1%E7%A0%81%E7%9A%84%E5%8E%9F%E5%9B%A0/</guid>
      <description>一、计算机中的显示原理 要想在计算机的显示器上显示文字，首先你得写一个程序，这个程序的任务就是就是把文字的显示信息发给显卡，显示信息包括在这个屏幕上的输出位置、字的大小等等。然后显卡就知道怎么显示这个字符了。
屏幕上是如何显示文字的原理是什么呢？ 屏幕上其实有很多个小灯，小到肉眼看不见，当他们不亮时，屏幕就是黑色的，当他们亮了一部分，如果那一部分刚好是个文字的形状，那么屏幕上就显示文字了。这个原理就跟军训时人摆文字显示字符一样。如下图，通过led灯的开和关显示出了123。放到显示器上，小灯会变得特变小，肉眼很难看到，当一部分红色的小灯亮了，那一部分刚好摆成123的形状，那么红色的123这三个字符就在屏幕上显示出来了。
如何让显示器得知道是那个灯亮那个灯灭，这就是显卡的作用了，操作系统会根据文字的编码，去字库中找到要显示的字符的点阵数据，点阵数据指明了哪个灯应该亮起，亮起的颜色是什么颜色。显卡会结合点阵数据和其他显示信息，进行计算（比如按照一定比例扩大等），然后发给显示器控制显示器的显示！ 注意：这一部分的具体细节我不确定，但是大概的思路应该是没错的。
通过以上得知，关键点在于文字的编码，只要知道了文字的编码，就能找到字库的点阵数据。众所周知，文字的编码有很多种，而乱码的根本原因是文件保存时采用的编码和打开文件时用于解码的编码不一致，从而找到了错误的点阵数据，显示了错误的输出！。
二、从键盘输入开始理解编码的存在形式 以window系统为例，假设你刚刚打开了记事本。 1.你在键盘上按下了’a‘。
2.你的按下触发了电路，键盘扫描到你a被按下，于是键盘形成了’a’的扫描码，发送到了存在于键盘上的寄存器，同时给CPU发送了一个中断信号，告诉CPU我这有活动了！
3.CPU根据键盘的中断线路号检测到是键盘发出的中断信号，于是根据中断号计算出键盘的中断处理程序在内存中的地址，转到键盘的中断处理程序去执行。
4.键盘的中断处理程序找到键盘的驱动程序代码，转到键盘的驱动程序执行。
5.键盘的驱动程序去读取键盘上的保存扫描码的寄存器，把‘a’的扫描码读到内存中。
6.驱动程序把扫描码转换成虚拟码。为什么要转换呢，因为不同的键盘由于厂家不同，型号不同、设计不同的原因，‘a’这个按键产生的扫描码在不同的键盘上是不一样的，为了统一管理，驱动程序得把不同键盘按下的‘a’转换成统一的表示。比如把不同键盘按下的‘a’产生的扫描码统一转换成一个字节的0x41。驱动程序要进行转换，那么驱动程序得知道这是哪种类型的键盘，不然没有转换的依据，原理是键盘的相关信息比如生产厂家、键盘型号等会保存在键盘上的一些只读寄存器中，计算机通过这些只读寄存器就知道这是哪种键盘。从而就知道该键盘的扫描码对应的虚拟码。
7.驱动程序把0x41交给操作系统上自带的且在后台默默运行的的IMM进程。
8.IMM进程把0x41交给系统当前使用的的输入法编辑器。比如搜狗输入法或者百度输入法。系统上所有的输入法，都由IMM管理。
9.输入法收到了0x41，对0x41进行处理，霹雳巴拉一顿操作，首先查到0x41这个值对应的可能的文字，比如可能是‘啊’、‘阿’、‘吖‘…等。首先查询系统当前的代码页是哪一个，也就是系统默认编码，若你没有修改系统的默认编码，则查找的结果为GBK（相当于GB2312）编码的。于是通过GBK的代码页这些可能的文字的GBK编码找出来，通过操作系统从字库中寻找这些可能文字的字库数据，交给显卡，显卡把他们显示出来。
10.显卡把他们显示出来后，屏幕上显示了好多个文字让你选择，那么你通过键盘的左移右移回车等操作选中了一个字，这个键盘操作又产生扫描码，最后还是输入法接收到了你的键盘按键输入情况，然后，输入法就可以根据你的键盘输入情况确定你选中了哪个文字，假设你选中了’啊’，于是输入法把‘啊’这个字的GBK码交给操作系统，操作系统把这个GBK码放进指定内存中，这指定内存被称为输入缓冲区。
11.记事本可以扫描缓冲区有没有内容，当检测到了缓冲区有了内容后，记事本至少需要两个操作，一是把‘啊’这个文字显示到记事本的窗口里面，二是把&amp;quot;啊&amp;quot;的编码放到自己的内存空间。
12.记事本接收到的是GBK编码，这个编码保存在了记事本的内存空间，并把“啊”输出到了记事本的窗口中。这时你的输入操作已经结束了（如果你不再进行输入），接下来就是保存这个记事本的内容了，如果想要保存这个“啊”，你的应用程序就得向操作系统申请一个文件，把“啊”的编码写进文件中。如果你不作任何操作，硬盘上就会默认保存的是‘啊’的GBK编码，如果你想保存的是’啊’的其他编码，那也可以，转换一下编码格式，然后放进文件中保存。放进文件中保存，那c语言来说，有二进制方式的写和文本文件方式的写，该用什么方式呢？首先说明什么是文本文件，文本文件就是保存文本的文件，里边都是一些字符(也就是文本)的编码，解析出来后都是文字，你用utf-8格式保存的，里边就是utf-8格式的字符的编码，你用GBK格式保存的，里边就是GBK的编码，总之里边保存的是文字信息。另一个就是二进制文件，一般来说我们编程很少用到。二进制文件里边保存到不是文本，比如视频文件、图片文件、3D模型等。其实二进制文件和文本文件在文件中的保存形式都是0和1的二进制流，既然都是0和1的二进制流，为什么要区分他们呢，因为他们有点区别，比如文本文件以EOF（值为-1）作为文件结束标志，因为不管是什么编码，都没有哪个字符的编码值是-1。而二进制流就不一样了，里边完全有可能有一段字节代表着-1，因此不能以-1作为文件的结束标志，一般来说二进制文件应该是通过比较文件长度来判断结束标志的。在c语言中，我们通常是使用fwrite()和fread()函数来读写文件，那么我们并没有指明以什么编码方式来读出或写进文件啊，别忘了，两个函数会是系统调用相关的，而系统默认的编码格式就是GBK，因此这两个函数都是按GBK来进行读或取的。如果你想使用其他编码比如UNICODE，就得使用其他读写的函数了，比如fgetwc()、fwscanf();这些函数会把GBK编码转换成UNICODE编码再进行读和写。
13.记事本默认保存的编码是ANSI，ANSI也叫多字节字符集，ANSI其实不是一种编码方式，是所有使用不定长字节来表示字符的编码格式的统称，在简体中文Windows操作系统上，ANSI指的是GBK编码，在繁体中文Windows操作系统中，ANSI编码代表Big5；在日文Windows操作系统中，ANSI 编码代表 JIS 编码。当然你用可以更改记事本的保存格式。Unicode同理，Unicode是一个字符集，不是一个编码方式，在windows这边，Unicode指的是UTF-16，在其他环境下，可能指的是UTF-8或UTF-32,比如linux上指的是utf-8. | | | | | 三.缕一缕编程的过程 1.首先，现在我们简化一下VS2013这个软件，把VS2013看成是记事本（编辑器）+编译器的结合体。它只有编写文本进行保存和对文本文件进行编译的功能。如果你使用的是中文操作系统的Windowsd的VS2013编写源代码，在你编写完成后，运行之前或者按下CTRL+S,那么你的源代码就会保存起来。跟记事本的保存一样，那么它默认应该是使用GBK编码格式来保存你的代码源文件，那我不想按GBK来保存怎么办呢？可以在文件-&amp;gt;高级配置选项里修改源代码的保存格式。 2.假设你的源代码里有一个字符&amp;quot;你好&amp;quot;，在你把你的源代码保存了之后，硬盘上你的源代码文件中存在着&amp;quot;你好，世界！&amp;ldquo;的GBK编码：C4E3(你） BAC3（好） 。
3.你的打印文件里面有打印&amp;quot;你好&amp;quot;这个中文字符的语句，你想在屏幕上显示&amp;quot;你好&amp;rdquo;
4.你点击了运行按钮，首先，编译器的做的工作就是启动它的编译器对你的源代码进行编译，要进行编译，首先得解析源代码文件，要解析一个文件，得先知道它是什么编码，否则解析要出错啊，那么编译器是按什么编码格式来解析你的源文件呢，不用想就知道，那肯定是GBK编码嘛，毕竟编辑器的默认编码就是GBK的。那我要是把编辑器的编码格式换了怎么办呢，没事，编译器改成一样的不就完事了。修改的方式为项目 -&amp;gt; 属性 -&amp;gt; 配置属性 -&amp;gt; c/c++ -&amp;gt; 命令行 -&amp;gt; 其他选项。在其他选项里输入你所需要的编码，比如utf-8。
一般这一行是空的，我们只需把“从父级或项目默认设置继承”选上就好了。这样它就会根据你项目的编码格式主动更改相同的编码进行解析。
4.等等，你好像记得有个地方也能修改项目的编码属性？就在项目 -&amp;gt; 属性 -&amp;gt; 配置属性 -&amp;gt; 常规 -&amp;gt;字符集那，有个使用多字节字符集和使用Unicode字符集？它默认也不是GBK啊，它默认是Unicode呢。这又是什么玩意？首先，在这里，多字节字符集=ANSI=GBK,Unicode=utf-16。这玩意是这样的，它不是设置你写的代码的编码格式，但是他能控制你使用的API的版本。什么意思呢？你写的程序肯定有#include&amp;lt;“xxx”&amp;gt;的代码，#号说明这是一个预编译命令，c语言里可没有#这个操作符。预编译命令是给编译器看的，编译器检测到了预编译命令后，在链接的时候就会把#include&amp;lt;“xxx”&amp;gt;删掉，把#include&amp;lt;“xxx”&amp;gt;原本的代码复制过来放到这个地方。预编译指令还有一个较为常见的就是#ifndef。完整意思就是if not define,字面上来理解就是如果没有定义。而在vs上编程你经常#incluide&amp;lt;“xxx”&amp;gt;里边的代码里经常有和以下类似的代码： ifndef Unicode typedef MessageBox MessageBoxA #endif typedef MessageBox MessageBoxW
翻译如下： 如果没有定义 Unicode MessageBox 就是MessageBoxA 结束 MessageBox 就是 MessageBoxW</description>
    </item>
    
    <item>
      <title>分布式理论的简单理解</title>
      <link>https://ikebo.cc/post/migrate/part2/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA%E7%9A%84%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3/</link>
      <pubDate>Fri, 07 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA%E7%9A%84%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3/</guid>
      <description>一个分布式系统里面，节点组成的网络本来应该是连通的。然而可能因为一些故障，使得有些节点之间不连通了，整个网络就分成了几块区域。数据就散布在了这些不连通的区域中。这就叫分区。
当你一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了。这时分区就是无法容忍的。
提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，这一数据项就可能分布到各个区里。容忍性就提高了。
然而，要把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的。要保证一致，每次写操作就都要等待全部节点写成功，而这等待又会带来可用性的问题。
总的来说就是，数据存在的节点越多，分区容忍性越高，但要复制更新的数据就越多，一致性就越难保证。为了保证一致性，更新所有节点数据所需要的时间就越长，可用性就会降低。
转载自知乎</description>
    </item>
    
    <item>
      <title>生命的意义</title>
      <link>https://ikebo.cc/post/migrate/part2/%E7%94%9F%E5%91%BD%E7%9A%84%E6%84%8F%E4%B9%89/</link>
      <pubDate>Wed, 20 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E7%94%9F%E5%91%BD%E7%9A%84%E6%84%8F%E4%B9%89/</guid>
      <description>生命在于运动，及早睡早起
运动代表生命的活力和激情
早睡代表自律
早起代表积极的生活态度，精进</description>
    </item>
    
    <item>
      <title>我的大学</title>
      <link>https://ikebo.cc/post/migrate/part2/%E6%88%91%E7%9A%84%E5%A4%A7%E5%AD%A6/</link>
      <pubDate>Tue, 28 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E6%88%91%E7%9A%84%E5%A4%A7%E5%AD%A6/</guid>
      <description>本文转载自徐宥的我的大学
我的大学 虽然标题是”我的大学”，但大学中的一切，其实都和大学前的经历和学习习惯有关。因此，我还是从我小学时的一件对我以后人生，包括大学影响巨大的事情说起吧。
数理化和好老爸
我的小学是在农村里和爷爷奶奶度过的。我的父母住在小镇上，两人平时都要工作，没空照看我和我弟弟。所以，我只有周末和放假才到镇上，和父母弟弟在一起。四年级升五年级那个暑假，我到了镇上，和父母在一起。因为一起抓鱼钓虾的玩伴都在老家，百无聊赖的我开始乱翻父亲的书橱，找书看。某天，我翻出了一本叫做《平面几何一题多解》的书，那是本封面很好看的书。我把整本书翻下来，每个汉字我都认识，但每个符号我都不懂。好奇的我于是问父亲，这个书讲的是什么呀，怎么从来没见过这些奇怪的符号呢？ 他就告诉我说，书里讲解的这个东西，叫平面几何。他接着问我说，“平面几何是个很有趣的东西，你想不想学呢？” 我说，当然想啊。那时的我，其实只是一个好奇的小学生，迫切想知道这个书中的图画和符号的意思。我肯定不会想到，这个很随意的决定，改变了我其后的整个人生。
听了我肯定的回答，我父亲立即从书橱里层（我家书太多了，书橱太小，书橱里书分里层外层，外层的书挡住了内层的书脊，我从来都不知道里面还有宝贝）变戏法一般的翻出了本《数理化自学丛书–平面几何》。对于我父亲这一代人来说，《数理化自学丛书》是代表着知识，荣耀和梦想的。我感觉他翻出这本书的时候的动作是虔诚的，但当时的我并不知道我父亲在这套书上寄托的希冀和梦想。我只记得他告诉我，当年这套书，用去了他大半个月工资。就这样，从五年级开始，我就在父亲的指点下，开始蹒跚前进学习《平面几何》。从一开始不知道什么叫 “证明”， 需要他一字一句帮我厘清逻辑关系，到后来全是自学不需要他教，我很快就喜欢上了自学这种学习方式，每天自己看书并且做八道题。暑假过完后，我就回到了爷爷奶奶的老家。父亲让我继续自学，并且布置我一周做八道题。我在爷爷奶奶家，每天放学回来不做家庭作业也不看动画片，就赶紧做一道几何题。做几何题的妙趣，是不融入其中的人不能理解的。比起小学里的抄生字，抄课文这种作业，做几何题是脑力和体力的双重享受。当时，我周围没人可以讨论切磋，全靠自己。遇到不会的题目，我只能自己冥思苦想，或者熬到周末和父亲讨论，因此，常常被一道难题从周一折腾到周日。好在这套书是粉碎四人帮后出的第一版，当年学生的数学水平比不上现在的学生，而这本书又是以自学为主要切入点，所以题目相对也简单，我冥思苦想几天后大体上也能想到解题思路。因此，我能够常常体验百思得解的愉悦感。我觉得，这种时常拜访的愉悦感，让我很早就开始相信独立思考的力量。
每个周末，父亲都用吱吱作响的自行车带我到镇上洗澡理发，然后批改上周我做的几何题。在自行车上的时候，他常常信马由缰，随口说些说些初中物理和初中代数知识，比如看到船就说浮力，看到马就说做功，看到三角形就说余弦定理等等。我也就半懂不懂的听，有时候插几句话，有时候能睡着了，没有丝毫的压力和拘束。很早就被中学数学物理知识装备的一个小学生是可怕的，我那时候觉得知识就是力量，因此我一定要用自己的数学物理知识做一台柴油机，我很自信的认为我懂得做柴油机和机动车的一切知识，说不定还能做出第二类永动机。我爸爸屡次告诉我不可行，而我反过来一直屡次告诉他，你是个没有理想的人。我爸爸不愿意打消我的理想，只是扔给我更多的书，希望能够打击我制造柴油机和永动机的热情，而我的知识理想，在读了更加多的书以后，变得更加的坚固了，我相信，学习知识是我人生第一重要事，有了知识，虽然不一定能做柴油机，但一定能做更多强大的事情。同时，我通过学习几何和其他的一些父亲扔给我的书，开始对自己的学习能力有了自信，我相信，找书自学是学知识的好方法，同时，把题从头到尾做一遍是很好的自学方法。
所以，我带着三个理念进入了大学，第一是什么东西都可以自学，第二是慢即是快，笨笨的做一遍题是学习的捷径；第三是知识理想主义，知识就是力量。而读书学知识能够消除蒙昧，掌握改变世界的力量，所以是一件快乐的事情。
大一，极端自负和极端自卑
我的高考成绩还很不错，高中还拿了一个数学联赛一等奖，所以，我是带着对自己数学知识（为了准备数学竞赛，我看了很多闲书，有很多就是大学数学系的教材）和学习方法的自信满满，和对南大数学系这个相对不好的选择的遗憾和自卑（当时的高考分数可以填报更加好的学校或更加喜欢的专业）来到大学的。当时我的心理状态可以用八个字概括: 极端自负，极端自卑。 这种心态，一直笼罩了我上大学的头两年，而且总是以一季度为周期，在两极之间交替变化。我在学期开始往往很自负，到期中考试左右很自卑，然后再自负，再自卑，不断反复。
在我看来，极端自负这个心态，其实不是因为自信，而是因为极端自卑生出的应激反应–为了掩盖自卑，只好用自负来掩饰。为什么我极端自卑呢，大体来自两个方面，一个是我的成绩排名在高中都是很前的，但是到了大学就 20 名开外了。尽管我觉得自己的数学水平很不错，考试却总是不怎么样，觉得考试考不出真水平。另一个是觉得自己没有在一个自己满意的系。我喜欢动手的工科，当时我觉得比起计算机系和电子系这样的“牛” 系，数学系并不“牛”。可即使在不牛的系，我都不能做到前10，更别说看上去更加牛的计算机系了。为了掩饰这种这种自卑，就自然生出了极端自负。那时候，我上课根本不听讲，理由是“书上的东西太简单了”。为了证明自己智商还可以，我总是坐在最后一排，显示自己并不热心于老师讲课。我这样持续了两年， 以至于到最后， 我连班上每次都坐在前面的几个同学的名字都不知道。这样的心态明明是错的，我却缺少一个很好的动因来改变它。
不过最原始的三个理念还是在的，我告诫自己即使不听讲，也不能浪费时间。所以，我把听课做作业上节省下来的时间，用在了看喜欢的计算机书和学习编程上了。于是，整个大一大二，我凭借着简单的自学的理念，开始了两件事情，敲 《Thinking in Java》(TIJ) 和 《The TeXbook》 上的没一个样例。
敲 TIJ 的机缘其实很简单，我是在软件学院听课的时候看到他们教 Java, 但是他们用的 《Java 大学教程》太贵了，我舍不得买。 我在网上搜了一圈，发现 《Thinking in Java》是一个免费的英文电子书。 于是，我就在数学系的机房，每天下午和晚上，开着一台计算机，屏幕上放着这个电子书，再用我的很土的笔记本，运行着未注册的 JCreator, 一个字母一个字母的敲 TIJ 上面的程序。我很偏激的认为拷贝粘帖的程序记不住，所以每个字母都自己手敲。 就这样，花了一个学期，居然就把所有的程序敲完了，基本上 Java 的方方面面，我也了然于胸了。
敲完 Thinking in Java 之前没几天，我们就期末考试了。那一次考试的试题是 LaTeX 排版的，而不是手写的。 我考试的时候就问监考老师这玩意怎么排版出来的，因为我知道 Word 这个软件做不到这个效果。监考老师除了对我不认真考试表示不满外， 还算仁慈，告诉了我 LaTeX 这个名词。 寒假里，我就买了一本 LaTeX 教程。然后，突然认识到，原来 TeX 居然是我最热爱的 Knuth 的杰作，于是我就疯狂的开始学 TeX。 我的方法还是一样， 敲例子。 记得 TeXbook 上有一个程序， Knuth 让大家自己照着敲入计算机， 然后还很幽默的说，实验证明，只有很少的人会按照他说的敲入这个程序，而这部分人，却是学 TeX 最好的人。看到这里我会心一笑，觉得自己的方法原来也不算笨。从此，一字不漏敲入一本书的程序成了我推荐别人学习语言的最好办法。 我后来大四又敲了 A Byte of Python，前段时间又敲玩了 The Awk Book，都是不到一个月瞬间从初学者成为细节很熟悉顺手拈来使用者。顺着这个方法，大二我把 《组合数学引论》 和上海交通大学出版的一本 《离散数学》 上的题目都做一题不漏做完了。当时选者两本书也没有特别的目的，就觉得这东西应该是计算机的数学基础。这些积累，在大四全部都显现了出来。</description>
    </item>
    
    <item>
      <title>What the heck is the event loop?</title>
      <link>https://ikebo.cc/post/migrate/part2/what-the-heck-is-the-event-loop/</link>
      <pubDate>Fri, 17 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/what-the-heck-is-the-event-loop/</guid>
      <description>前几天看了一个youtube视频，关于JavaScript运行原理的，讲的比较透彻，在此记录一下。
这位老兄为此还写了一个可以实时看到js运行时动画的程序，实属牛逼。
这位老兄的博客地址：http://latentflip.com</description>
    </item>
    
    <item>
      <title>NodeJS架构 - 单线程事件循环模型</title>
      <link>https://ikebo.cc/post/migrate/part2/nodejs%E6%9E%B6%E6%9E%84-%E5%8D%95%E7%BA%BF%E7%A8%8B%E4%BA%8B%E4%BB%B6%E5%BE%AA%E7%8E%AF%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Wed, 08 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/nodejs%E6%9E%B6%E6%9E%84-%E5%8D%95%E7%BA%BF%E7%A8%8B%E4%BA%8B%E4%BB%B6%E5%BE%AA%E7%8E%AF%E6%A8%A1%E5%9E%8B/</guid>
      <description>这篇译章探究了NodeJS的架构和单线程事件循环模型。我们将在本文中讨论“NodeJS如何在底层工作，它遵循什么类型的处理模型，NodeJS如何使用单线程模型处理并发请求”等内容。
NodeJS 单线程事件循环模型 正如我们刚才说的，NodeJS使用的是“单线程事件循环模型”的架构去处理多个并发的客户端请求的。
有许多Web应用程序技术，如JSP，Spring MVC，ASP.NET等。但所有这些技术都遵循“多线程请求 - 响应”架构来处理多个并发客户端。
我们已经熟悉“多线程请求 - 响应”架构，因为它被大多数Web应用程序框架使用。 但是为什么NodeJS选择了不同的架构来开发Web应用程序。多线程和单线程事件循环体系结构之间的主要区别是什么?
NodeJS NodeJS使用“单线程事件循环模型”架构来处理多个并发客户端。然而它是如何真正处理并发客户端请求且不使用多个线程。什么是事件循环模型？我们将逐一讨论这些概念。
在讨论“单线程事件循环”架构之前，首先我们将介绍著名的“多线程请求 - 响应”架构。
传统的Web应用处理模型 任何非NodeJS开发的Web应用程序通常都遵循“多线程请求 - 响应”模型。我们可以将此模型称为请求/响应模型。
客户端向服务器发送请求，然后服务器根据客户端请求进行一些处理，准备响应并将其发送回客户端。
该模型使用HTTP协议。由于HTTP是无状态协议，因此该请求/响应模型也是无状态模型。所以我们可以将其称为请求/响应无状态模型。
但是，此模型使用多线程来处理并发客户端请求。 在讨论这个模型内部之前，首先要看下面的内容。
请求/响应模型处理的步骤: 客户端发送一个请求到Web服务器 Web服务器内部维护一个有限的线程池，以便在客户端请求提供服务 Web服务器处于无限循环中并等待客户端传入请求 Web服务器处理请求步骤: 接收到一个客户端请求 从线程池中选择一个线程 将此线程分配给客户端请求 此线程读取客户端请求，处理客户端请求，执行阻塞的IO操作(如果需要)和准备响应 此线程将准备好的请求发送回Web服务器 Web服务器又将此响应发送到相应的服务器 服务器为所有客户端执行以上步骤，为每一个客户端请求创建一个线程。
图表说明:
Client-1, Client-2, &amp;hellip;, Client-n是同时发送请求到Web服务器的客户端应用 Web服务器内部维护着一个有限的线程池，线程池中线程数量为m个 Web服务器逐个接收这些请求: Web服务器拾取Client-1的请求Request-1，从线程池中拾取一个线程T-1并将此请求分配给线程T-1 线程T-1读取Client-1的请求Request-1, 并处理该请求 该请求无阻塞IO处理 处理完必要的步骤后准备将Response-1发送回客户端 Web服务器又将此Response-1发送到Client-1 Web服务器拾取Client-2的请求Request-2，从线程池中拾取一个线程T-2并将此请求分配给线程T-2 线程T-2读取Client-2的请求Request-2, 并处理该请求 该请求无阻塞IO处理 处理完必要的步骤后准备将Response-2发送回客户端 Web服务器又将此Response-2发送到Client-2 Web服务器拾取Client-n的请求Request-n，从线程池中拾取一个线程T-n并将此请求分配给线程T-n 线程T-n读取Client-n的请求Request-n, 并处理该请求 Request-n需要大量的阻塞IO和计算操作 线程T-n需要更多时间与外部系统(SQL, File System)交互，执行必要步骤并准备Response-n并将其发送回服务器 Web服务器又将此Response-n发送到Client-n 如果&amp;rsquo;n&amp;rsquo;大于&amp;rsquo;m&amp;rsquo;（大多数时候,它是真的），则在使用完所有的m个线程之后，剩余的客户端请求会在队列中等待。
如果这些线程中有大量的阻塞IO操作(例如:和数据库、文件系统、外部服务等交互)，那么剩余的客户端也会等待更长的时间。
一旦线程池中的线程空闲且可用于下一个任务，服务器就会拾取这些线程并将它们分配给剩余的客户端请求。 每个线程都会使用到许多资源，如内存等。因此，在将这些线程从忙状态转到等待状态之前，它们应该释放所有获取的资源。 请求/响应无状态模型的缺点：
在处理越来越多的并发客户端请求时会变得棘手 当客户端请求增加时，线程也会越来越多，最后它们会占用更多内存。 客户端可能需要等待服务器释放可用的线程去处理其请求 处理阻塞式的IO任务时浪费时间 NodeJS的架构 - 单线程事件循环 NodeJS不遵循请求/响应多线程无状态模型。 它采用单线程与事件循环模型。 NodeJS的处理模型主要基于Javascript基于事件的模型和Javascript回调机制。</description>
    </item>
    
    <item>
      <title>V8 Ignition：JS 引擎与字节码的不解之缘</title>
      <link>https://ikebo.cc/post/migrate/part2/v8-ignitionjs-%E5%BC%95%E6%93%8E%E4%B8%8E%E5%AD%97%E8%8A%82%E7%A0%81%E7%9A%84%E4%B8%8D%E8%A7%A3%E4%B9%8B%E7%BC%98/</link>
      <pubDate>Wed, 08 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/v8-ignitionjs-%E5%BC%95%E6%93%8E%E4%B8%8E%E5%AD%97%E8%8A%82%E7%A0%81%E7%9A%84%E4%B8%8D%E8%A7%A3%E4%B9%8B%E7%BC%98/</guid>
      <description>http://arewefastyet.com 网站测试并展示了数个 JavaScript 引擎的性能数据，是各家 JS 引擎性能的比武场：
我们看到在这个比武场上，最近 Chrome 出现了多个新条目，其中很多条目都是关于 v8 的 Ignition 新架构的组合，他们是 v8 引擎最近推出的 JS 字节码解释器。
纵览各个 JS 引擎的实现，我们发现基于字节码的实现是主流。例如苹果公司的 JavaScriptCore （JSC） 引擎，2008 年时他们引入了 SquirrelFish（市场名 Nitro），实现了一个字节码寄存器机（Register Machine）。再如 Mozilla 公司的 SpiderMonkey，他们使用字节码的历史更久，可以追溯到 1998 年的 Netscape 4（见 https://dxr.mozilla.org/classic/source/js/src/jsemit.c ），SpiderMonkey 实现的是堆栈机（Stack Machine）。微软的 Chakra 也使用了字节码，他们实现的是寄存器机（Register Machine）。而 v8 之前的做法是比较“脱俗”的，他们跳过了字节码这一层，直接把 JS 编译成机器码。而在刚刚过去的五一假日前夕，v8 5.9 发布了，其中的 Ignition 字节码解释器将默认启动 ：https://v8project.blogspot.co.id/2017/04/v8-release-59.html 。v8 自此回到了字节码的怀抱。
这让笔者不禁怀念起 2007 年 Ruby 1.9 的发布。当时 Ruby 1.9 也是第一次引入了字节码，名为 YARV，由笹田耕一领导主导开发完成。当时，Ruby 还在使用松本行弘的初级的解释器实现，亦即，解释器每次遍历代码的抽象语法树（AST）来进行 Ruby 代码的解释执行。而 YARV 则把抽象语法树（AST）先编译成字节码，然后再运行。引入字节码之后，Ruby 的性能得到了显著的提升。
而这次 V8 引入字节码却是向着相反的方向后退。因为之前 v8 选择了直接将 JS 代码编译到机器代码执行，机器码的执行性能已经非常之高，而这次引入字节码则是选择编译 JS 代码到一个中间态的字节码，执行时是解释执行，性能是低于机器代码的。最终的性能测试势必会降低，而不是提高。那么 V8 为什么要做这样一个退步的选择呢？为 V8 引入字节码的动机又是什么呢？笔者总结下来有三条：</description>
    </item>
    
    <item>
      <title>v8与webkit的关系</title>
      <link>https://ikebo.cc/post/migrate/part2/v8%E4%B8%8Ewebkit%E7%9A%84%E5%85%B3%E7%B3%BB/</link>
      <pubDate>Wed, 08 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/v8%E4%B8%8Ewebkit%E7%9A%84%E5%85%B3%E7%B3%BB/</guid>
      <description>Part11 Chrome页面的绘制（绘制，就是把一个HTML文件变成一个活灵活现的页面展示的过程&amp;hellip;），只有一半轮子是Chrome自己做的，还有一部分来自于WebKit，这个Apple打造的Web渲染器。。。
之所以说是一半轮子来源于WebKit，是因为WebKit本身包含两部分主要内容，一部分是做Html渲染的，另一部分是做JavaScript解析的。在Chrome中，只有Html的渲染采用了WebKit的代码，而在JavaScript上，重新搭建了一个NB哄哄的V8引擎。目标是，用WebKit + V8的强强联手，打造一款上网冲浪的法拉利，从效果来看，还着实做的不错。。。
不过，虽说Chrome和WebKit都是开源的，并联手工作。但是，Chrome还是刻意的和WebKit保持了距离，为其始乱终弃埋下了伏笔。Chrome在WebKit上封装了一层，称为WebKit Glue。Glue层中，大部分类型的结构和接口都和WebKit类似，Chrome中依托WebKit的组件，都只是调用WebKit Glue层的接口，而不是直接调用WebKit中的类型。按照Chrome自己文档中的话来说，就是，虽然我们再用WebKit实现页面的渲染，但通过这个设计（加一个间接层&amp;hellip;）已经从某种程度大大降低了与WebKit的耦合，使得可以很容易将WebKit换成某个未来可能出现的更好的渲染引擎。。。
Part22 我们知道不同浏览器用的不同的渲染引擎：
Tridend(IE)、Gecko(FF)、WebKit(Safari,Chrome,Andriod浏览器)
当然 Chrome 重构了一下 WebKit 然后管它叫 Blink。但是大体架构还是和 WebKit 一致的。
我们看看我们常说的 V8 和 WebKit 有什么关系吧。
下面是 WebKit 的大致结构：
实线框内模块是所有移植的共有部分，虚线框内不同的厂商可以自己实现。
就是说 JS 引擎(JS 虚拟机)，WebKit 是默认的是 JSCore，而 Google 则自己实现了一版吊炸天的 V8。
因此虽然同样是WebKit，Safari 用的是 JSCore, Chrome 用的是 V8。
v8与webkit的关系&amp;#160;&amp;#x21a9;&amp;#xfe0e;
webkit vs v8&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>我为什么而奋斗</title>
      <link>https://ikebo.cc/post/migrate/part2/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E8%80%8C%E5%A5%8B%E6%96%97/</link>
      <pubDate>Sun, 29 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E8%80%8C%E5%A5%8B%E6%96%97/</guid>
      <description>今天偶尔看到当时字节的简历筛选截图，一点感想，记录一下
我没有家庭背景，没有学校背景。
我所做的只是为了证明，自己并不比那些有学校背景的人差，这件事我从大学入学就开始做，一直到现在，期间虽然有所懈怠，但大方向并没有变。
这个过程会很累，也比较漫长，但这是我一定要做的事情。
我需要付出更多的努力，做到一般人做不到的事情。
途径是什么呢，最主要的就是代码了吧，去开源社区，创造自己的一点影响力。
别让自己再被别人瞧不起，这是我想做的，也是我一直会坚持的。
加油吧，这条路，也许会越走越孤独，但这就是你阿。</description>
    </item>
    
    <item>
      <title>Ubuntu16.04 编译shadowsocks-libev</title>
      <link>https://ikebo.cc/post/migrate/part2/ubuntu16.04-%E7%BC%96%E8%AF%91shadowsocks-libev/</link>
      <pubDate>Thu, 05 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/ubuntu16.04-%E7%BC%96%E8%AF%91shadowsocks-libev/</guid>
      <description>记录一下
安装依赖 apt install -y gettext build-essential autoconf pkg-config libtool libpcre3-dev asciidoc xmlto libev-dev libc-ares-dev automake libmbedtls-dev libsodium-dev 下载代码 git clone https://github.com/shadowsocks/shadowsocks-libev.git cd shadowsocks-libev git submodule update --init --recursive //下载子模块 编译 ./autogen.sh ./configure make &amp;amp;&amp;amp; make install </description>
    </item>
    
    <item>
      <title>权限系统与RBAC模型概述</title>
      <link>https://ikebo.cc/post/migrate/part2/%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E4%B8%8Erbac%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0/</link>
      <pubDate>Wed, 14 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E4%B8%8Erbac%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0/</guid>
      <description>前言 一年前，我负责的一个项目中需要权限管理。当时凭着自己的逻辑设计出了一套权限管理模型，基本原理与RBAC非常相似，只是过于简陋。当时google了一些权限管理的资料，从中了解到早就有了RBAC这个东西。可惜一直没狠下心来学习。
更详细的RBAC模型非常复杂。本文只做了一些基础的理论性概述。本文资料完全来自互联网。
权限系统与RBAC模型概述 RBAC（Role-Based Access Control ）基于角色的访问控制。
在20世纪90年代期间，大量的专家学者和专门研究单位对RBAC的概念进行了深入研究，先后提出了许多类型的RBAC模型，其中以美国George Mason大学信息安全技术实验室（LIST）提出的RBAC96模型最具有系统性，得到普遍的公认。
RBAC认为权限的过程可以抽象概括为：判断【Who是否可以对What进行How的访问操作（Operator）】这个逻辑表达式的值是否为True的求解过程。
即将权限问题转换为Who、What、How的问题。who、what、how构成了访问权限三元组。
RBAC支持公认的安全原则：最小特权原则、责任分离原则和数据抽象原则。
最小特权原则得到支持，是因为在RBAC模型中可以通过限制分配给角色权限的多少和大小来实现，分配给与某用户对应的角色的权限只要不超过该用户完成其任务的需要就可以了。 责任分离原则的实现，是因为在RBAC模型中可以通过在完成敏感任务过程中分配两个责任上互相约束的两个角色来实现，例如在清查账目时，只需要设置财务管理员和会计两个角色参加就可以了。 数据抽象是借助于抽象许可权这样的概念实现的，如在账目管理活动中，可以使用信用、借方等抽象许可权，而不是使用操作系统提供的读、写、执行等具体的许可权。但RBAC并不强迫实现这些原则，安全管理员可以允许配置RBAC模型使它不支持这些原则。因此，RBAC支持数据抽象的程度与RBAC模型的实现细节有关。 RBAC96是一个模型族，其中包括RBAC0~RBAC3四个概念性模型。
基本模型RBAC0定义了完全支持RBAC概念的任何系统的最低需求。
RBAC1和RBAC2两者都包含RBAC0，但各自都增加了独立的特点，它们被称为高级模型。
RBAC1中增加了角色分级的概念，一个角色可以从另一个角色继承许可权。
RBAC2中增加了一些限制，强调在RBAC的不同组件中在配置方面的一些限制。
RBAC3称为统一模型，它包含了RBAC1和RBAC2，利用传递性，也把RBAC0包括在内。这些模型构成了RBAC96模型族。
RBAC模型简述
RBAC0的模型中包括用户（U）、角色（R）和许可权（P）等3类实体集合。
RABC0权限管理的核心部分，其他的版本都是建立在0的基础上的，看一下类图：
RBAC0定义了能构成一个RBAC控制系统的最小的元素集合。
在RBAC之中,包含用户users(USERS)、角色roles(ROLES)、目标objects(OBS)、操作operations(OPS)、许可权permissions(PRMS)五个基本数据元素，此模型指明用户、角色、访问权限和会话之间的关系。
每个角色至少具备一个权限，每个用户至少扮演一个角色；可以对两个完全不同的角色分配完全相同的访问权限；会话由用户控制，一个用户可以创建会话并激活多个用户角色，从而获取相应的访问权限，用户可以在会话中更改激活角色，并且用户可以主动结束一个会话。
用户和角色是多对多的关系，表示一个用户在不同的场景下可以拥有不同的角色。
例如项目经理也可以是项目架构师等；当然了一个角色可以给多个用户，例如一个项目中有多个组长，多个组员等。
这里需要提出的是，将用户和许可进行分离，是彼此相互独立，使权限的授权认证更加灵活。
角色和许可（权限）是多对多的关系，表示角色可以拥有多分权利，同一个权利可以授给多个角色都是非常容易理解的，想想现实生活中，当官的级别不同的权限的情景，其实这个模型就是对权限这方面的一个抽象，联系生活理解就非常容易了。
RBAC1，基于RBAC0模型，引入角色间的继承关系，即角色上有了上下级的区别，角色间的继承关系可分为一般继承关系和受限继承关系。一般继承关系仅要求角色继承关系是一个绝对偏序关系，允许角色间的多继承。而受限继承关系则进一步要求角色继承关系是一个树结构，实现角色间的单继承。
这种模型合适于角色之间的层次明确，包含明确。
RBAC2，基于RBAC0模型的基础上，进行了角色的访问控制。
RBAC2模型中添加了责任分离关系。RBAC2的约束规定了权限被赋予角色时，或角色被赋予用户时，以及当用户在某一时刻激活一个角色时所应遵循的强制性规则。责任分离包括静态责任分离和动态责任分离。约束与用户-角色-权限关系一起决定了RBAC2模型中用户的访问许可，此约束有多种。
互斥角色 ：同一用户只能分配到一组互斥角色集合中至多一个角色，支持责任分离的原则。互斥角色是指各自权限互相制约的两个角色。对于这类角色一个用户在某一次活动中只能被分配其中的一个角色，不能同时获得两个角色的使用权。常举的例子：在审计活动中，一个角色不能同时被指派给会计角色和审计员角色。 基数约束 ：一个角色被分配的用户数量受限；一个用户可拥有的角色数目受限；同样一个角色对应的访问权限数目也应受限，以控制高级权限在系统中的分配。例如公司的领导人有限的； 先决条件角色 ：可以分配角色给用户仅当该用户已经是另一角色的成员；对应的可以分配访问权限给角色，仅当该角色已经拥有另一种访问权限。指要想获得较高的权限，要首先拥有低一级的权限。就像我们生活中，国家主席是从副主席中选举的一样。 运行时互斥 ：例如，允许一个用户具有两个角色的成员资格，但在运行中不可同时激活这两个角色。 RBAC3，也就是最全面级的权限管理，它是基于RBAC0的基础上，将RBAC1和RBAC2进行整合了，最前面，也最复杂的：
综上为权限管理模型的相关介绍，其实在任何系统中都会涉及到权限管理的模块，无论复杂简单，我们都可以通过以RBAC模型为基础，进行相关灵活运用来解决我们的问题。
RBAC的优缺点
RBAC模型没有提供操作顺序控制机制。这一缺陷使得RBAC模型很难应用关于那些要求有严格操作次序的实体系统。
例如，在购物控制系统中要求系统对购买步骤的控制，在客户未付款之前不应让他把商品拿走。RBAC模型要求把这种控制机制放到模型
实用的RBAC模型的数据库建模 以下模型均来自于互联网
扩展RBAC用户角色权限设计方案 RBAC（Role-Based Access Control，基于角色的访问控制），就是用户通过角色与权限进行关联。简单地说，一个用户拥有若干角色，每一个角色拥有若干权限。这样，就构造成“用户-角色-权限”的授权模型。在这种模型中，用户与角色之间，角色与权限之间，一般者是多对多的关系。（如下图） 角色是什么？可以理解为一定数量的权限的集合，权限的载体。例如：一个论坛系统，“超级管理员”、“版主”都是角色。版主可管理版内的帖子、可管理版内的用户等，这些是权限。要给某个用户授予这些权限，不需要直接将权限授予用户，可将“版主”这个角色赋予该用户。当用户的数量非常大时，要给系统每个用户逐一授权（授角色），是件非常烦琐的事情。这时，就需要给用户分组，每个用户组内有多个用户。除了可给用户授权外，还可以给用户组授权。这样一来，用户拥有的所有权限，就是用户个人拥有的权限与该用户所在用户组拥有的权限之和。（下图为用户组、用户与角色三者的关联关系） 在应用系统中，权限表现成什么？对功能模块的操作，对上传文件的删改，菜单的访问，甚至页面上某个按钮、某个图片的可见性控制，都可属于权限的范畴。有些权限设计，会把功能操作作为一类，而把文件、菜单、页面元素等作为另一类，这样构成“用户-角色-权限-资源”的授权模型。而在做数据表建模时，可把功能操作和资源统一管理，也就是都直接与权限表进行关联，这样可能更具便捷性和易扩展性。（见下图） 请留意权限表中有一列“权限类型”，我们根据它的取值来区分是哪一类权限，如“MENU”表示菜单的访问权限、“OPERATION”表示功能模块的操作权限、“FILE”表示文件的修改权限、“ELEMENT”表示页面元素的可见性控制等。 这样设计的好处有二。其一，不需要区分哪些是权限操作，哪些是资源，（实际上，有时候也不好区分，如菜单，把它理解为资源呢还是功能模块权限呢？）。其二，方便扩展，当系统要对新的东西进行权限控制时，我只需要建立一个新的关联表“权限XX关联表”，并确定这类权限的权限类型字符串。 这里要注意的是，权限表与权限菜单关联表、权限菜单关联表与菜单表都是一对一的关系。（文件、页面权限点、功能操作等同理）。也就是每添加一个菜单，就得同时往这三个表中各插入一条记录。这样，可以不需要权限菜单关联表，让权限表与菜单表直接关联，此时，须在权限表中新增一列用来保存菜单的ID，权限表通过“权限类型”和这个ID来区分是种类型下的哪条记录。 到这里，RBAC权限模型的扩展模型的完整设计图如下： 随着系统的日益庞大，为了方便管理，可引入角色组对角色进行分类管理，跟用户组不同，角色组不参与授权。例如：某电网系统的权限管理模块中，角色就是挂在区局下，而区局在这里可当作角色组，它不参于权限分配。另外，为方便上面各主表自身的管理与查找，可采用树型结构，如菜单树、功能树等，当然这些可不需要参于权限分配。
百度百科所示的模型 本文参考文献中的一种设计 辨析：角色与用户组有何区别？
两者的主要差别是：用户组是用户的集合，但不是许可权的集合；而角色却同时具有用户集合和许可权集合的概念，角色的作用把这两个集合联系在一起的中间媒介。
在一个系统中，如果用户组的许可权和成员仅可以被系统安全员修改的话，在这种机制下，用户组的机制是非常接近于角色的概念的。角色也可以在用户组的基础上实现，这有利于保持原有系统中的控制关系。在这种情况下，角色相当于一个策略部件，与用户组的授权及责任关系相联系，而用户组是实现角色的机制，因此，两者之间是策略与实现机制之间的关系。
ACL模型 访问控制列表，是前几年盛行的一种权限设计，它的核心在于用户直接和权限挂钩。</description>
    </item>
    
    <item>
      <title>权限系统设计模型分析（DAC，MAC，RBAC，ABAC）</title>
      <link>https://ikebo.cc/post/migrate/part2/%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90dacmacrbacabac/</link>
      <pubDate>Wed, 14 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E6%9D%83%E9%99%90%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90dacmacrbacabac/</guid>
      <description>术语 这里对后面会用到的词汇做一个说明，老司机请直接翻到常见设计模式。
用户 发起操作的主体。
对象（Subject） 指操作所针对的客体对象，比如订单数据或图片文件。
权限控制表 (ACL: Access Control List) 用来描述权限规则或用户和权限之间关系的数据表。
权限 (Permission) 用来指代对某种对象的某一种操作，例如“添加文章的操作”。
权限标识 权限的代号，例如用“ARTICLE_ADD”来指代“添加文章的操作”权限。
常见设计模式 自主访问控制（DAC: Discretionary Access Control） 系统会识别用户，然后根据被操作对象（Subject）的权限控制列表（ACL: Access Control List）或者权限控制矩阵（ACL: Access Control Matrix）的信息来决定用户的是否能对其进行哪些操作，例如读取或修改。
而拥有对象权限的用户，又可以将该对象的权限分配给其他用户，所以称之为“自主（Discretionary）”控制。
这种设计最常见的应用就是文件系统的权限设计，如微软的NTFS。
DAC最大缺陷就是对权限控制比较分散，不便于管理，比如无法简单地将一组文件设置统一的权限开放给指定的一群用户。
Windows的文件权限
强制访问控制（MAC: Mandatory Access Control） MAC是为了弥补DAC权限控制过于分散的问题而诞生的。在MAC的设计中，每一个对象都都有一些权限标识，每个用户同样也会有一些权限标识，而用户能否对该对象进行操作取决于双方的权限标识的关系，这个限制判断通常是由系统硬性限制的。比如在影视作品中我们经常能看到特工在查询机密文件时，屏幕提示需要“无法访问，需要一级安全许可”，这个例子中，文件上就有“一级安全许可”的权限标识，而用户并不具有。
MAC非常适合机密机构或者其他等级观念强烈的行业，但对于类似商业服务系统，则因为不够灵活而不能适用。
RedHat MLS
Red Hat: MLS
基于角色的访问控制（RBAC: Role-Based Access Control) 因为DAC和MAC的诸多限制，于是诞生了RBAC，并且成为了迄今为止最为普及的权限设计模型。
RBAC在用户和权限之间引入了“角色（Role）”的概念（暂时忽略Session这个概念）：
RBAC核心设计
图片来自Apache Directory
如图所示，每个用户关联一个或多个角色，每个角色关联一个或多个权限，从而可以实现了非常灵活的权限管理。角色可以根据实际业务需求灵活创建，这样就省去了每新增一个用户就要关联一遍所有权限的麻烦。简单来说RBAC就是：用户关联角色，角色关联权限。另外，RBAC是可以模拟出DAC和MAC的效果的。
例如数据库软件MongoDB便是采用RBAC模型，对数据库的操作都划分成了权限（MongoDB权限文档）：
权限标识 说明 find 具有此权限的用户可以运行所有和查询有关的命令，如：aggregate、checkShardingIndex、count等。 insert 具有此权限的用户可以运行所有和新建数据有关的命令：insert和create等。 collStats 具有此权限的用户可以对指定database或collection执行collStats命令。 viewRole 具有此权限的用户可以查看指定database的角色信息。 … 基于这些权限，MongoDB提供了一些预定义的角色（MongoDB预定义角色文档，用户也可以自己定义角色）：
角色 find insert collStats viewRole … read ✔ ✔ … readWrite ✔ ✔ ✔ … dbAdmin ✔ ✔ … userAdmin ✔ … 最后授予用户不同的角色，就可以实现不同粒度的权限分配了。</description>
    </item>
    
    <item>
      <title>单点登录SSO原理</title>
      <link>https://ikebo.cc/post/migrate/part2/%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95sso%E5%8E%9F%E7%90%86/</link>
      <pubDate>Wed, 30 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95sso%E5%8E%9F%E7%90%86/</guid>
      <description>背景 在企业发展初期，企业使用的系统很少，通常一个或者两个，每个系统都有自己的登录模块，运营人员每天用自己的账号登录，很方便。 但随着企业的发展，用到的系统随之增多，运营人员在操作不同的系统时，需要多次登录，而且每个系统的账号都不一样，这对于运营人员 来说，很不方便。于是，就想到是不是可以在一个系统登录，其他系统就不用登录了呢？这就是单点登录要解决的问题。
单点登录英文全称Single Sign On，简称就是SSO。它的解释是：在多个应用系统中，只需要登录一次，就可以访问其他相互信任的应用系统。
如图所示，图中有4个系统，分别是Application1、Application2、Application3、和SSO。Application1、Application2、Application3没有登录模块，而SSO只有登录模块，没有其他的业务模块，当Application1、Application2、Application3需要登录时，将跳到SSO系统，SSO系统完成登录，其他的应用系统也就随之登录了。这完全符合我们对单点登录（SSO）的定义。
技术实现 在说单点登录（SSO）的技术实现之前，我们先说一说普通的登录认证机制。 如上图所示，我们在浏览器（Browser）中访问一个应用，这个应用需要登录，我们填写完用户名和密码后，完成登录认证。这时，我们在这个用户的session中标记登录状态为yes（已登录），同时在浏览器（Browser）中写入Cookie，这个Cookie是这个用户的唯一标识。下次我们再访问这个应用的时候，请求中会带上这个Cookie，服务端会根据这个Cookie找到对应的session，通过session来判断这个用户是否登录。如果不做特殊配置，这个Cookie的名字叫做jsessionid，值在服务端（server）是唯一的。
同域下的单点登录 一个企业一般情况下只有一个域名，通过二级域名区分不同的系统。比如我们有个域名叫做：a.com，同时有两个业务系统分别为：app1.a.com和app2.a.com。我们要做单点登录（SSO），需要一个登录系统，叫做：sso.a.com。
我们只要在sso.a.com登录，app1.a.com和app2.a.com就也登录了。通过上面的登陆认证机制，我们可以知道，在sso.a.com中登录了，其实是在sso.a.com的服务端的session中记录了登录状态，同时在浏览器端（Browser）的sso.a.com下写入了Cookie。那么我们怎么才能让app1.a.com和app2.a.com登录呢？这里有两个问题：
Cookie是不能跨域的，我们Cookie的domain属性是sso.a.com，在给app1.a.com和app2.a.com发送请求是带不上的。 sso、app1和app2是不同的应用，它们的session存在自己的应用内，是不共享的。 那么我们如何解决这两个问题呢？针对第一个问题，sso登录以后，可以将Cookie的域设置为顶域，即.a.com，这样所有子域的系统都可以访问到顶域的Cookie。我们在设置Cookie时，只能设置顶域和自己的域，不能设置其他的域。比如：我们不能在自己的系统中给baidu.com的域设置Cookie。
Cookie的问题解决了，我们再来看看session的问题。我们在sso系统登录了，这时再访问app1，Cookie也带到了app1的服务端（Server），app1的服务端怎么找到这个Cookie对应的Session呢？这里就要把3个系统的Session共享，如图所示。共享Session的解决方案有很多，例如：Spring-Session。这样第2个问题也解决了。
同域下的单点登录就实现了，但这还不是真正的单点登录。
不同域下的单点登录 同域下的单点登录是巧用了Cookie顶域的特性。如果是不同域呢？不同域之间Cookie是不共享的，怎么办？
这里我们就要说一说CAS流程了，这个流程是单点登录的标准流程。 上图是CAS官网上的标准流程，具体流程如下：
用户访问app系统，app系统是需要登录的，但用户现在没有登录。 跳转到CAS server，即SSO登录系统，以后图中的CAS Server我们统一叫做SSO系统。 SSO系统也没有登录，弹出用户登录页。 用户填写用户名、密码，SSO系统进行认证后，将登录状态写入SSO的session，浏览器（Browser）中写入SSO域下的Cookie。 SSO系统登录完成后会生成一个ST（Service Ticket），然后跳转到app系统，同时将ST作为参数传递给app系统。 app系统拿到ST后，从后台向SSO发送请求，验证ST是否有效。 验证通过后，app系统将登录状态写入session并设置app域下的Cookie。 至此，跨域单点登录就完成了。以后我们再访问app系统时，app就是登录的。接下来，我们再看看访问app2系统时的流程。
用户访问app2系统，app2系统没有登录，跳转到SSO。 由于SSO已经登录了，不需要重新登录认证。 SSO生成ST，浏览器跳转到app2系统，并将ST作为参数传递给app2。 app2拿到ST，后台访问SSO，验证ST是否有效。 验证成功后，app2将登录状态写入session，并在app2域下写入Cookie。 这样，app2系统不需要走登录流程，就已经是登录了。SSO，app和app2在不同的域，它们之间的session不共享也是没问题的。
有的同学问我，SSO系统登录后，跳回原业务系统时，带了个参数ST，业务系统还要拿ST再次访问SSO进行验证，觉得这个步骤有点多余。他想SSO登录认证通过后，通过回调地址将用户信息返回给原业务系统，原业务系统直接设置登录状态，这样流程简单，也完成了登录，不是很好吗？
其实这样问题时很严重的，如果我在SSO没有登录，而是直接在浏览器中敲入回调的地址，并带上伪造的用户信息，是不是业务系统也认为登录了呢？这是很可怕的。
总结 单点登录（SSO）的所有流程都介绍完了，原理大家都清楚了。总结一下单点登录要做的事情：
单点登录（SSO系统）是保障各业务系统的用户资源的安全 。 各个业务系统获得的信息是，这个用户能不能访问我的资源。 单点登录，资源都在各个业务系统这边，不在SSO那一方。 用户在给SSO服务器提供了用户名密码后，作为业务系统并不知道这件事。 SSO随便给业务系统一个ST，那么业务系统是不能确定这个ST是用户伪造的，还是真的有效，所以要拿着这个ST去SSO服务器再问一下，这个用户给我的ST是否有效，是有效的我才能让这个用户访问。 本文转载自阿里云社区</description>
    </item>
    
    <item>
      <title>MySQL 如何对order by优化</title>
      <link>https://ikebo.cc/post/migrate/part2/mysql-%E5%A6%82%E4%BD%95%E5%AF%B9order-by%E4%BC%98%E5%8C%96/</link>
      <pubDate>Sun, 20 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/mysql-%E5%A6%82%E4%BD%95%E5%AF%B9order-by%E4%BC%98%E5%8C%96/</guid>
      <description>对于order by的优化，MySQL若可以利用索引的有序性进行排序，则优先使用索引进行排序，这种情况的执行效率是最快的；若无法有效利用索引的情况下，MySQL主要有3排序种算法对其进行优化每个算法都有一定的适用场景。
一、 利用索引排序 B-tree索引可以很好的支持单点查询、范围查询、有序性查询。所以对于order by 的排序查询，我们可以利用B-tree的有序性来有效的利用索引进行排序查询。当然，如果可以利用索引进行排序对我们的SQL查询本身也是有一定的要求限制的。
1.1 利用索引排序的特点 排序列必须有B-tree索引 如果为多表关联查询，排序列必须是对驱动表字段的排序 1.2、示例 ##建表语句，sbtest3与sbtest4表字段与索引一致，sbtest3的表数据量为30000，sbtest4的表数据量为60000 CREATE TABLE `sbtest4` ( `id` int(11) NOT NULL AUTO_INCREMENT, `k` int(11) NOT NULL DEFAULT &amp;#39;0&amp;#39;, `c` char(120) NOT NULL DEFAULT &amp;#39;&amp;#39;, `pad` char(60) NOT NULL DEFAULT &amp;#39;&amp;#39;, PRIMARY KEY (`id`), KEY `k_4` (`k`) ) ENGINE=InnoDB AUTO_INCREMENT=62768 DEFAULT CHARSET=utf8mb4 ##单表排序查询 ##order by字段为B-tree索引字段，可以看到执行计划有效利用了索引进行排序查询 root@mysql57 13:25: [db2]&amp;gt; explain select * from sbtest4 t4 order by t4.k desc limit 5; +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+-------+ | 1 | SIMPLE | t4 | NULL | index | NULL | k_4 | 4 | NULL | 5 | 100.</description>
    </item>
    
    <item>
      <title>块存储、文件存储和对象存储</title>
      <link>https://ikebo.cc/post/migrate/part2/%E5%9D%97%E5%AD%98%E5%82%A8%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%92%8C%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E5%9D%97%E5%AD%98%E5%82%A8%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%92%8C%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/</guid>
      <description>块存储 典型设备：磁盘阵列、硬盘
块存储主要是将裸磁盘空间整个映射给主机使用的，就是说例如磁盘阵列里面有5块硬盘（为方便说明，假设每个硬盘1G），然后可以通过划逻辑盘、做Raid、或者LVM（逻辑卷）等种种方式逻辑划分出N个逻辑的硬盘。（假设划分完的逻辑盘也是5个，每个也是1G，但是这5个1G的逻辑盘已经于原来的5个物理硬盘意义完全不同了。例如第一个逻辑硬盘A里面，可能第一个200M是来自物理硬盘1，第二个200M是来自物理硬盘2，所以逻辑硬盘A是由多个物理硬盘逻辑虚构出来的硬盘。）
接着块存储会采用映射的方式将这几个逻辑盘映射给主机，主机上面的操作系统会识别到有5块硬盘，但是操作系统是区分不出到底是逻辑还是物理的，它一概就认为只是5块裸的物理硬盘而已，跟直接拿一块物理硬盘挂载到操作系统没有区别的，至少操作系统感知上没有区别。
此种方式下，操作系统还需要对挂载的裸硬盘进行分区、格式化后，才能使用，与平常主机内置硬盘的方式完全无异。
优点：
这种方式的好处当然是因为通过了Raid与LVM等手段，对数据提供了保护。 另外也可以将多块廉价的硬盘组合起来，成为一个大容量的逻辑盘对外提供服务，提高了容量。 写入数据的时候，由于是多块磁盘组合出来的逻辑盘，所以几块磁盘可以并行写入的，提升了读写效率。 很多时候块存储采用SAN架构组网，传输速率以及封装协议的原因，使得传输速度与读写速率得到提升。 缺点：
采用SAN架构组网时，需要额外为主机购买光纤通道卡，还要买光纤交换机，造价成本高。 主机之间的数据无法共享，在服务器不做集群的情况下，块存储裸盘映射给主机，再格式化使用后，对于主机来说相当于本地盘，那么主机A的本地盘根本不能给主机B去使用，无法共享数据。 不利于不同操作系统主机间的数据共享：另外一个原因是因为操作系统使用不同的文件系统，格式化完之后，不同文件系统间的数据是共享不了的。例如一台装了WIN7/XP，文件系统是FAT32/NTFS，而Linux是EXT4，EXT4是无法识别NTFS的文件系统的。就像一只NTFS格式的U盘，插进Linux的笔记本，根本无法识别出来。所以不利于文件共享。 文件存储 典型设备：FTP、NFS服务器
为了克服上述文件无法共享的问题，所以有了文件存储。
文件存储也有软硬一体化的设备，但是其实普通拿一台服务器/笔记本，只要装上合适的操作系统与软件，就可以架设FTP与NFS服务了，架上该类服务之后的服务器，就是文件存储的一种了。
主机A可以直接对文件存储进行文件的上传下载，与块存储不同，主机A是不需要再对文件存储进行格式化的，因为文件管理功能已经由文件存储自己搞定了。
优点：
造价交低：随便一台机器就可以了，另外普通以太网就可以，根本不需要专用的SAN网络，所以造价低。 方便文件共享：例如主机A（WIN7，NTFS文件系统），主机B（Linux，EXT4文件系统），想互拷一部电影，本来不行。加了个主机C（NFS服务器），然后可以先A拷到C，再C拷到B就OK了。（例子比较肤浅，请见谅……） 缺点：
读写速率低，传输速率慢：以太网，上传下载速度较慢，另外所有读写都要1台服务器里面的硬盘来承担，相比起磁盘阵列动不动就几十上百块硬盘同时读写，速率慢了许多。
对象存储 典型设备：内置大容量硬盘的分布式服务器
对象存储最常用的方案，就是多台服务器内置大容量硬盘，再装上对象存储软件，然后再额外搞几台服务作为管理节点，安装上对象存储管理软件。管理节点可以管理其他服务器对外提供读写访问功能。
之所以出现了对象存储这种东西，是为了克服块存储与文件存储各自的缺点，发扬它俩各自的优点。简单来说块存储读写快，不利于共享，文件存储读写慢，利于共享。能否弄一个读写快，利于共享的出来呢。于是就有了对象存储。
首先，一个文件包含了了属性（术语叫metadata，元数据，例如该文件的大小、修改时间、存储路径等）以及内容（以下简称数据）。
以往像FAT32这种文件系统，是直接将一份文件的数据与metadata一起存储的，存储过程先将文件按照文件系统的最小块大小来打散（如4M的文件，假设文件系统要求一个块4K，那么就将文件打散成为1000个小块），再写进硬盘里面，过程中没有区分数据/metadata的。而每个块最后会告知你下一个要读取的块的地址，然后一直这样顺序地按图索骥，最后完成整份文件的所有块的读取。
这种情况下读写速率很慢，因为就算你有100个机械手臂在读写，但是由于你只有读取到第一个块，才能知道下一个块在哪里，其实相当于只能有1个机械手臂在实际工作。
而对象存储则将元数据独立了出来，控制节点叫元数据服务器（服务器+对象存储管理软件），里面主要负责存储对象的属性（主要是对象的数据被打散存放到了那几台分布式服务器中的信息），而其他负责存储数据的分布式服务器叫做OSD，主要负责存储文件的数据部分。当用户访问对象，会先访问元数据服务器，元数据服务器只负责反馈对象存储在哪些OSD，假设反馈文件A存储在B、C、D三台OSD，那么用户就会再次直接访问3台OSD服务器去读取数据。
这时候由于是3台OSD同时对外传输数据，所以传输的速度就加快了。当OSD服务器数量越多，这种读写速度的提升就越大，通过此种方式，实现了读写快的目的。
另一方面，对象存储软件是有专门的文件系统的，所以OSD对外又相当于文件服务器，那么就不存在文件共享方面的困难了，也解决了文件共享方面的问题。
所以对象存储的出现，很好地结合了块存储与文件存储的优点。
最后为什么对象存储兼具块存储与文件存储的好处，还要使用块存储或文件存储呢？
有一类应用是需要存储直接裸盘映射的，例如数据库。因为数据库需要存储裸盘映射给自己后，再根据自己的数据库文件系统来对裸盘进行格式化的，所以是不能够采用其他已经被格式化为某种文件系统的存储的。此类应用更适合使用块存储。 对象存储的成本比起普通的文件存储还是较高，需要购买专门的对象存储软件以及大容量硬盘。如果对数据量要求不是海量，只是为了做文件共享的时候，直接用文件存储的形式好了，性价比高。 </description>
    </item>
    
    <item>
      <title>文件怎么在不同的文件系统间转存</title>
      <link>https://ikebo.cc/post/migrate/part2/%E6%96%87%E4%BB%B6%E6%80%8E%E4%B9%88%E5%9C%A8%E4%B8%8D%E5%90%8C%E7%9A%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E9%97%B4%E8%BD%AC%E5%AD%98/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E6%96%87%E4%BB%B6%E6%80%8E%E4%B9%88%E5%9C%A8%E4%B8%8D%E5%90%8C%E7%9A%84%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E9%97%B4%E8%BD%AC%E5%AD%98/</guid>
      <description>文件 文件是一堆有特定格式的数据，在硬盘中由一堆特定顺序的磁盘块组成。
文件系统 文件系统是操作系统用于明确存储设备（常见的是磁盘，也有基于NAND Flash的固态硬盘）或分区上的文件的方法和数据结构；即在存储设备上组织文件的方法。
同一个文件，文件内容肯定相同，放在不同的文件系统中，不同的是文件内容的存放方式。
when a file is copied between different filesystem types, the content isn&amp;rsquo;t changed, only the way the file is written to disk.
举个具体的例子，本机磁盘有两个分区，格式化成不同的文件系统，当把一个文件从其中一个分区拷贝到另一个分区时，完全可以，文件内容一样，不同的是文件在磁盘中的组织方式，而且这种组织方式的不同对用户是透明的，我们只需要关注文件内容和格式本身，不需要关注文件所处的文件系统。</description>
    </item>
    
    <item>
      <title>软件制图方法</title>
      <link>https://ikebo.cc/post/migrate/part2/%E8%BD%AF%E4%BB%B6%E5%88%B6%E5%9B%BE%E6%96%B9%E6%B3%95/</link>
      <pubDate>Mon, 17 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E8%BD%AF%E4%BB%B6%E5%88%B6%E5%9B%BE%E6%96%B9%E6%B3%95/</guid>
      <description>前言 “架构制图”这词乍一听似乎有些晦涩，但如果提起“工程制图”，相信绝大部分工科背景的程序员们都不会陌生，甚至还能共同感慨下那些年一起伏在宿舍左手圆规，右手直尺，徒手作图到深夜的日子。
软件工程也是工程，因此传统工程制图的一些基本理论，在软件行业同样适用。但另一方面，软件与实体制造业之间还是有着本质区别，所以在制图方面的需求和方式也大相径庭，无法直接套用。作为软件行业的从业者，你可以完全不懂工程制图，但你不得不懂架构制图 —— 这是任何程序员职业生涯的的必修课。
本文在后半段将介绍如何用图去描述（describe）和传达（communicate）你的架构设计。值得强调的是，本文并不会侧重于单一的方法和工具，而是更希望关注那些优秀方法背后的通用方法论，即架构制图的本质、共性和最佳实践。希望本文能起到引子作用，激发大家对自己日常工作中关于架构和制图部分的关注、审视与思考；如果还真能帮助大家提升一点点制图效率和效果，那就更好不过了。
什么是软件架构？ 1. 软件架构定义 IEEE 给出的定义：架构是环境中该系统的一组基础概念（concepts）和属性（properties），具体表现就是它的元素（elements）、关系（relationships），以及设计与演进的基本原则（principles）。
CMU 软件工程研究院的定义：架构是用于推演出该系统的一组结构（structures），具体是由软件元素（elements）、元素之间的关系（relationships），以及各自的**属性（properties）**共同组成。
Uncle Bob 在 Clean Architecture 一书中给出的定义：架构是创建者给予该系统的形态（shape）。这个形态的具体形式来源于对系统组件（components）的划分和排列，以及这些组件之间互相通讯的方式。
2. 架构核心要素 综合上述各种权威定义，软件系统的架构通常需要包含如下四类核心要素：
元素（elements）：将系统拆分为一组元素 - 模块、组件、结构体、子系统； 关系（relationships）：不同元素之间的关系 - 交互、依赖 、继承、组合、聚合； 属性（properties）：每个元素具备的属性 - 名称、职责、接口、实现限制等； 原理（principles）：为什么这么设计 - 拆分依据、设计原则、决策原因等。 为什么架构很重要？ 1. 架构是系统实现的蓝图 最近有部很火的网剧叫《摩天大楼》，讲述了一段匪夷所思的悬疑故事。为什么扯这个呢？因为我想借用这个剧的标题来问个问题：摩天大楼是由谁建起来的？也许你心里会默念：废话，不就是建筑工人们一砖一瓦堆起来的嘛。仔细再想想？背后是不是还有一堆操碎了心的建筑设计师（比如剧中帅气的林大森）和土木工程师们？他们虽然不搬砖也不扛水泥，但如果没有他们产出的那些繁琐严谨的设计图纸，摩天大楼是是不可能像农村自建房一样仅凭工人们各自的经验与想象力就能快速平稳地竖立起来的。
正是靠着这些图纸所描绘出来的工程蓝图（blueprints），才让成百上千工人们的分工合作和验收标准有了依据：大家只需要照着蓝图，按部就班地把自己所负责的那些砖瓦添上去就行了；只要蓝图正确，且施工过程也没有偏差，最终顺利完工只是个时间问题。
与建筑、汽车或者任何其他工程行业一样，软件在落地实现（编码）之前也需要先有蓝图；而其中最重要的一份蓝图，就是架构设计。没有架构，仅凭程序员自己脑子里的模糊设想，也许你可以像传统手艺人一样独自创造出一些美好有用的小东西（比如 Linux 0.01 版本），但不太可能以工程的方式协同一个团队共同建造起一个与摩天大楼规模类似的复杂软件系统（比如现代的 Linux 系统）。一方面，人类的思维能力终归有限，必须依靠架构这种高度抽象和简化的蓝图，才能让复杂系统的创造、理解、分析和治理变得可行；另一方面，量级达到一定程度的大型系统，也只能依靠多人分工合作才能完成，而架构也正是多人沟通协作的重要基础。
2. 架构是沟通协作的基础 软件项目的最终价值产出就是软件系统，而架构作为软件系统的灵魂和骨架，可以起到如下作用：
理解对齐：所有软件系统的目的都是为了实现用户需求，但实现的途径有无限种可能性（相比传统工程行业，软件的灵活性更大、知识迭代更快）。架构设计就是去选择其中一条最合适的实现途径，因此其中会涉及非常多关键的选路决策（为什么要这么拆分？为什么选择 A 技术而不是 B？）。这些重要的技术决策需要通过架构描述这种形式被记录和同步，才能让项目组所有成员对整个系统的理解对齐，形成共识。 工作量化：项目管理最重要的步骤之一就是工时评估，它是确定项目排期和里程碑的直接依据。显然，只通过 PRD / 交互图是无法科学量化出项目工作量的，因为很难直观判断出一句简短需求或一个简单页面背后，究竟要写多少代码、实现起来难度有多大。有了清晰明确的架构之后，理论上绝大部分开发工作都能做到可见、可预测和可拆解，自然而然也就能够被更准确地量化。当然，精准的工作量评估在 IT 行业内也一直是个未解之谜，实际的工期会受太多未知因素影响，包括程序员的技能熟练度、心情好不好、有没有吃饱等。 标准术语：编程作为一种具有创造力的工作，从某种角度看跟写科幻小说是类似的。好的科幻小说都喜欢造概念，比如三体中的智子，如果没看过小说肯定不知道这是个啥玩意儿。软件系统在造概念这一点上，相比科幻小说只有过之而无不及，毕竟小说里的世界通常还是以现实为背景，而软件中的世界就全凭造物者（程序员）的想象（建模）了。稍微复杂一点的软件系统，都会引入一些领域特定甚至全新创作的概念。为了避免在项目过程中出现鸡同鸭讲的沟通障碍和理解歧义，就必须对描述这些概念的术语进行统一。而架构的一个重要目的，就是定义和解释清楚系统中涉及的所有关键概念，并在整个架构设计和描述过程中使用标准和一致的术语，真正做到让大家的沟通都在一个频道上。 言之有物：就跟讨论产品交互时需要对着原型图、讨论代码细节时需要直接看代码一样，架构是在讨论一些较高维技术问题时的必要实物（具体的实物化形式就是所谓架构描述）。否则，要么一堆人对着空气谈（纸上谈兵都说不上），要么每次沟通时都重新找块白板画一画（费时费力且容易遗落信息，显然不是长久之计）。 知识沉淀 &amp;amp; 新人培训：架构应该被作为与代码同等重要的文档资产持续沉淀和维护，同时也是项目新人快速理解和上手系统的重要依据。不要让你的系统跟公司内某些祖传遗留系统一样 —— 只有代码遗留了下来，架构文档却没有；只能靠一些口口相传的残留设计记忆，苦苦维系着项目的生命延续。 3. 架构决定了产品质量 如何衡量一个软件产品的质量？上图是 ISO/IEC 25010 标准定义的软件产品质量模型，包括以下 8 个大类：</description>
    </item>
    
    <item>
      <title>goroutine 记录</title>
      <link>https://ikebo.cc/post/migrate/part2/goroutine-%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Thu, 06 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/goroutine-%E8%AE%B0%E5%BD%95/</guid>
      <description>作者回复: 所以说不要用“协程”这个概念，因为“协程（coroutine）”指的是程序在同一个线程内的自行调度，是应用程序本身完全可控的。而 goroutine 的调度是 Go 语言的运行时系统发起的。
你不要揣测 Go 语言的调度器会怎样调度。你首先要知道哪些代码点是调度的时机（注意，到了调度时机也不一定发生调度，只是时机而已）。你还要知道如果想让多个 goroutine 按照你拟定的流程执行就需要用到 Channel 以及各种同步工具。
你说的“跳转到”只能在 coroutine 场景下才能这么说。在 goroutine 的场景下，没有“跳转”这么一说。
其一，你在上面的 for 语句中启用了一个 goroutine，你怎么就能断定后面的代码一定会先于这个 go 函数执行？不要做这种假设。因为连 goroutine 的调度都是并发的。
其二，两个 goroutine 一个 channel，一个 goroutine 发，一个 goroutine 取。这个 ch1 什么时候满、什么时候空，你基本上是确定不了的。因为两个 for 循环 在迭代的过程中都可能因被调用而换下 CPU。
其三，你要知道，几乎任何函数调用都存在调度时机，更何况是像 fmt.Println 这种需要 I/O 的重型操作。所以，为什么你那前一个 for 循环结束之后就不能被调度了呢？
以上是我通过你的文字表达猜测并回答的，并不一定完全匹配你要问的问题。还有问题的话再问我。
我觉得你对“并发”和“调度”这两个概念不清楚。我建议你好好看看专栏里讲 goroutine 的那几篇文章。有必要的话，买我的《Go 并发编程实战》第二版从头学一下。
研究下各种协程的实现，以及goroutine的实现</description>
    </item>
    
    <item>
      <title>大厂晋升指南-职级详解</title>
      <link>https://ikebo.cc/post/migrate/part2/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97-%E8%81%8C%E7%BA%A7%E8%AF%A6%E8%A7%A3/</link>
      <pubDate>Tue, 04 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E5%A4%A7%E5%8E%82%E6%99%8B%E5%8D%87%E6%8C%87%E5%8D%97-%E8%81%8C%E7%BA%A7%E8%AF%A6%E8%A7%A3/</guid>
      <description>所有职级，能力可以分为3个维度，4个复杂度（COMD模型）
P5 在别人的知道下做事，主要在技术和业务上，技术80% 业务20%
P5 的核心能力要求是在别人的指导下完成任务，主要提升目标是从学生转变为“打工人”。
技术方面，P5 需要打好基础，学习岗位要求的基础技术。采用“碎片化时间，系统化学习”的方法提高你的技术学习效率。
业务方面，P5 需要熟悉各项业务功能的实现逻辑。对于 2C 业务，你要成为产品的深度用户；对于 2B 业务，你就要多跟客户交流。
管理方面，P5 的重点是熟悉项目流程，避免踩坑。你需要注意学习公司的管理制度。
P6 独挡一面
P6 的核心能力要求是独立负责端到端的项目任务，主要提升目标是成为独立自主的“项目能手”。
技术方面，P6 需要掌握团队用到的各种技术的“套路”，重点提升技术深度，学习时要避免贪多求全的心态，优先深入学习跟工作内容强相关的技术。
业务方面，P6 需要掌握某类业务相关的所有功能，并深度理解处理逻辑，主要的提升方法是“5W1H8C1D”分析法和竞品分析。
管理方面，P6 需要负责项目子任务推进，包括工作量评估、计划制定和沟通协调等。评估工作量的时候，建议使用 WBS 分解法，先拆解成容易评估的小任务，然后独立评估每项任务，最后汇总。
P7 P7 的核心能力要求是指挥单个团队达成目标，主要提升目标是成为让人信服的团队专家。
技术维度上，P7 需要精通团队相关的技术，重点提升技术宽度，主要提升方法是“比较学习法”。在这个阶段，你既要避免因为管理而丢掉技术，也要避免“生搬硬套”新技术。
业务维度上，P7 需要掌握业务整体情况，从用户特征、用户价值、获客方式和获利方式 4 个方面理解业务 6～12 个月的规划。对于 2C 业务，AARRR 漏斗模型是必须掌握的；对于 2B 业务，还应该了解行业强相关的手段和措施。
管理维度上，P7 需要负责指挥单个团队。对于担任 Team Leader 的 P7 来说，需要系统化地掌握管理的基本技能，避免事必躬亲或者做甩手掌柜；对于不是 Team Leader 的 P7 来说，要学会做一个靠谱的项目负责人。
P8 P8 的核心能力要求是指挥多个团队达成目标，主要提升目标是成为有影响力的领域专家。
技术维度上，P8 需要精通领域相关的技术，重点提升领域技术宽度，可以通过研究开源项目和参加技术大会来拓宽自己的技术宽度，也可以在技术大会上做主题演讲来提升自己的影响力。
业务维度上，P8 需要熟悉多个业务，并且开始需要掌握战略规划相关的技能，以帮助自己理解业务整体规划，可以采取“宝洁战略模型”的方法快速提升自己的业务理解力。
管理维度上，P8 需要负责指挥多个团队，提升自己管理技能的核心是学会抓住三个管理重点：搭建团队梯队，参与目标制定，关注技术演进。
P9 P9 的核心能力要求是导演成熟作品，主要提升目标是成为跨领域整合的业务导演。
技术维度上，P9 需要具备跨领域整合的能力，重点提升领域技术广度，可以通过环式学习法来提升自己的技术广度，通过关注和跟进新技术来提升自己的创新能力。</description>
    </item>
    
    <item>
      <title>来自极客时间的评论：认知天性：让学习变得轻而易举的心理学规律</title>
      <link>https://ikebo.cc/post/migrate/part2/%E6%9D%A5%E8%87%AA%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%E7%9A%84%E8%AF%84%E8%AE%BA%E8%AE%A4%E7%9F%A5%E5%A4%A9%E6%80%A7%E8%AE%A9%E5%AD%A6%E4%B9%A0%E5%8F%98%E5%BE%97%E8%BD%BB%E8%80%8C%E6%98%93%E4%B8%BE%E7%9A%84%E5%BF%83%E7%90%86%E5%AD%A6%E8%A7%84%E5%BE%8B/</link>
      <pubDate>Tue, 04 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E6%9D%A5%E8%87%AA%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%E7%9A%84%E8%AF%84%E8%AE%BA%E8%AE%A4%E7%9F%A5%E5%A4%A9%E6%80%A7%E8%AE%A9%E5%AD%A6%E4%B9%A0%E5%8F%98%E5%BE%97%E8%BD%BB%E8%80%8C%E6%98%93%E4%B8%BE%E7%9A%84%E5%BF%83%E7%90%86%E5%AD%A6%E8%A7%84%E5%BE%8B/</guid>
      <description>这本书介绍了各种高效学习的方法，其中有几种方法，比较颠覆认知，书中认为学习时，应该有间隔的进行，而非集中式的重复进行，这样带来的好处是：能带来更长久的记忆，也就是长期记忆，而集中式练习则是短期记忆。花十分钟记忆十个单词所留存的记忆，不如分两次五分钟记忆十个单词所留存的记忆来得深刻。理由是：长期记忆的形成，需要有个巩固的过程，可能是数小时，可能是数天，在这期间，记忆痕迹得到加深，所学的新知识与旧知识建立连接，带来稳固的长期记忆，因此不要频繁的进行集中式学习，而是有间隔的进行，频繁的集中练习只会带来短期记忆，有间隔的学习所耗费的精力远大于频繁的重复式学习，使用这种方式，学习起来也更加困难，但也不容易遗忘。理论上来说，遗忘的越多，重新回忆起来的难度越大，但所保持的效果越持久，不过，还是不要等到所学知识遗忘的差不多了后再去重新学习，那样的话，你基本回忆不起来，只能重新从头开始，得不偿失，等到所学知识有点儿遗忘再去学会比较好。
拿学习专栏来说，不要反复地去学习同一章节，而是有间隔地进行，这会带来长期记忆，在学完一章内容后，不要立刻练习所学内容，而是应该等遗忘一些后进行，效果要好于学完一章节后立刻进行练习的方式，学完后不容易忘，在学完后立刻进行练习，学完后容易忘。书中建议：学习知识或技能时，通过自我检测的方式，代替重复学习，并且有间隔地进行自测，就拿学习算法来说，不要一遍接一遍地重复去学，而应该在学习完某一算法后，通过自测的方式来逼迫自己的大脑去检索所学，拒绝机械式的重复重复再重复，这样所学的知识会更加稳固，留存的记忆更持久，书中还提到：自我检测后的延迟反馈会进一步加强学习效果，也就是在进行自测后，不要立马查看答案，而是应该间隔一段时间再查看。
在练习所学时，有顺序的练习比无顺序的练习效果差，且这期间，穿插不同类容类型的学习方式，所产生的效果，要比在熟练某一知识后，再进入下一学习内容的练习效果要好，不仅能保持长久的记忆，使所学知识不易遗忘，还能提高学习者的辨识能力，也就是在面对各种复杂问题时，能正确识别问题类型，根据所学知识，从脑海中搜寻出对应问题的解决方案。回想一下我们上学时的课本内容安排，都是有顺序地，由浅入深地进行，而我们在学习时，就是通过不断练习同一知识点直至完全掌握后，依次有顺序地进入下一知识点的学习，直到课程学完。这种通过大量练习同一类型的题目的方式，使我们在考试遇到时，能得心应手地解决，但面对综合题时，这些问题都被混合在了一起，且没有顺序，我们难以辨别题目真正要考察什么问题，无法辨别问题的类型，从而无法正确地运用所学知识解决问题。拿到生活上来说，你遇到的问题也是没有顺序，且都是混合在一起的，你难以辨别各个问题之间的差异，不清楚要解决的问题到底是什么，从而无法选取合适的解决方案解决问题。
面对这种现状，前面提到的穿插不同内容类型的学习方式能帮到你。简单来说，就是在当前学习内容掌握的还不熟练的情况下，跳入下一阶段的学习，这种方式比在当前学习内容练习熟练后，再顺序进入下一阶段的学习方式，效果要好。例如，你在学完数组，哈希表，树，堆等数据结构后，在练习时，要在数组还未掌握熟练时，就进入树的练习，而不是等到完全掌握熟练一项内容才进入下一阶段的练习，你不能每学一样知识，待熟练后才进入下一阶段，应该以随机非顺序的方式进行，这种非顺序的穿插不同类型的学习方式能促进知识的活学活用。
这种学习方式如果转换到专栏学习的话，相当于在一个章节内容还未熟练的情况下就要进入下一章节的学习，比如，在学习完专栏章节1，2，3后，从章节2开始练习，待初步掌握，还未熟练时，进入章节1的练习，然后在未熟练时又进入章节2的学习，这种在练习期间，穿插各种不同学习内容的方式，比大量练习同一主题内容完全熟练后，再进入别的主题学习，效果要好得多，书中说的是远好于。
这样看来，这种学习方式还是很适合学习难度高的专业知识的，它能使所学知识停留在长期记忆，并能促进知识的活学活用，你一定不想体会辛辛苦苦好不容易学完算法后，在下一次要用到时想不起来的尴尬境地，或者在遇到综合各种算法问题时，束手无措的苦苦挣扎，而以上的学习方式或许能帮到你。
总结：
间隔进行，更容易形成长期记忆 不能每学一样知识，待熟练后才进入下一阶段，应该以随机费顺序的方式进行。 有点道理阿。</description>
    </item>
    
    <item>
      <title>了解微型创业</title>
      <link>https://ikebo.cc/post/migrate/part2/%E4%BA%86%E8%A7%A3%E5%BE%AE%E5%9E%8B%E5%88%9B%E4%B8%9A/</link>
      <pubDate>Fri, 30 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E4%BA%86%E8%A7%A3%E5%BE%AE%E5%9E%8B%E5%88%9B%E4%B8%9A/</guid>
      <description>最近听了一场知乎live，讲的是微型创业，在此记录一下。
理解小众市场 微型创业首先是小，面向的是小众市场，一两个人就可以搞定。小的特点，就是成本低，灵活，针对性强，能解决特定问题。 如何发现/选择小众市场 发现需求而不是创造需求，发现需求就成功了一半
1.画个圈圈型
从自身爱好出发，有一双善于发现的眼睛，加上别有用心一点。
2.望远镜型
善于利用工具，利用微信指数了解热点，市场的变化。谷歌趋势，百度指数。
利用谷歌关键词发现市场，用谷歌搜索Instagram 发现关键词 Instagram download pictures， 继续谷歌，点开排名第一的网站，输入图片链接地址就可以下载下来。盈利方式就是谷歌的ad scene广告系统，每年人民币20w. 网上的资源和开源的工具都很多，如果你足够机智，肯定能用好网上的工具。
3.犀牛鸟型
共生关系，国际国内大象级app很多，微信、Facebook，YouTube，有人做微信机器人的额产品收入非常可观，通过机器人管理微信群消息。github搜索wxbot，找到相关代码资源。比如YouTube的视频转gif动图链接，每个月700万流量，7000美元一个月，YouTube mp3.org 输入视频提取音频，技术难度没有，月流量2.7亿，270万美元。这种做大象周边小众市场的例子还有很多，只要你多琢磨琢磨，一刀切进去肯定是有肉吃的。
4.总在河边走型
想做某个市场但是不懂，先勇敢地跳进去，然后再深入。比如跨境电商，赚差价。比如区块链，很多小白不懂区块链，但是需求很大，如果深入研究把东西教给大家。
验证需求 MVP 简单落地页 广告投放
重点：市场比你的产品要重要的多，一个没有市场的软件应用仅仅是个产品而已，大部分开发人员都是有个点子，花了几个月把产品做出来，结果发现没有人购买。这样的产品，即使花再大的力气也没什么卵用，产品成功的最重要因素，不是人，不是市场的运营也不是产品，而是 是否有一群人愿意付费购买。所以在确定不是伪需求之前一定要上个线，走两步，验证需求的第一步，mvp，就是最小化可行性产品，开发产品时最好先做一个原型。通过测试收集用户的反馈，快速迭代，最终适应市场的需求。做个独立页面，是否有用户原因购买，不需要开发完成。
营销和流量 建立跟踪，底层最重要的是数据，前提是建立好数据的跟踪。
最初的推广 Reddit Product Hunt v2ex
一定要和用户建立联系 浏览页面时弹出层，留下优享，数据证明非常有效
SEO 一定要优化，兵家必争之地，SEO做好会产生长期价值，时间长了会发现，每天的稳定流量大部分来自SEO，对于程序员没什么难度，认真做好每个细节就好。</description>
    </item>
    
    <item>
      <title>长连接和短连接</title>
      <link>https://ikebo.cc/post/migrate/part2/%E9%95%BF%E8%BF%9E%E6%8E%A5%E5%92%8C%E7%9F%AD%E8%BF%9E%E6%8E%A5/</link>
      <pubDate>Fri, 30 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E9%95%BF%E8%BF%9E%E6%8E%A5%E5%92%8C%E7%9F%AD%E8%BF%9E%E6%8E%A5/</guid>
      <description>首先，连接指的是传输层的TCP连接
连接就是连接，没有长短之说
是长是短取决于你是否关闭连接
建立连接后进行一次读写就马上关闭，这条连接对你来说就是短连接，如HTTP0.9, HTTP 1.0(默认关闭，支持Keep-Alive)就是这样
HTTP 1.1协议的headers中默认有Connection: Keep-Alive，告诉HTTP服务器不要关闭连接，后续的HTTP请求继续用这条连接，那这条连接对你来说就是一条长连接
另外，socket的SO_KEEPALIVE选项跟http中的Keep-Alive是完全不同的东西，前者是服务器在一条连接至少空闲2小时后发送探活包检测客户端是否还有响应，意在检测半开连接并关闭，后者前文应该已经说明白了。</description>
    </item>
    
    <item>
      <title>使用Privoxy转发http到socks</title>
      <link>https://ikebo.cc/post/migrate/part2/%E4%BD%BF%E7%94%A8privoxy%E8%BD%AC%E5%8F%91http%E5%88%B0socks/</link>
      <pubDate>Thu, 29 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E4%BD%BF%E7%94%A8privoxy%E8%BD%AC%E5%8F%91http%E5%88%B0socks/</guid>
      <description>国内服务器ping不通github，正好有一台香港的socks server，如果可以将http转发到这台server，问题就解决了。
privoxy是一款不进行网页缓存且自带过滤功能的代理服务器，针对http、https协议。通过其过滤功能，用户可以保护隐私、对网页内容进行过滤、管理Cookie，以及拦阻各种广告等。1
privoxy官网
大概意思是从http协议到其他协议的转换，另外可以做一些http内容的过滤、修改等。
安装privoxy（ubuntu）
apt-get install privoxy
默认privoxy服务已经通过systemctl管理，systemctl status/stop/start privoxy查看/停止/启动privoxy
配置文件在/etc/privoxy/config
在文件末尾加上forward-socks5 / host:port .
将host:port替换成你的socks local server 最后按个.表示转发到socks server之后不用再转发到某个http server了
如果想这个privoxy服务可以被外部访问的话，比如本机通过这个privoxy进行科学上网，可以将配置文件中listen-address 的localhost改成0.0.0.0
最后，重启服务: systemctl restart privoxy
https://zh.wikipedia.org/wiki/Privoxy&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>Java传递函数实现懒执行</title>
      <link>https://ikebo.cc/post/migrate/java%E4%BC%A0%E9%80%92%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0%E6%87%92%E6%89%A7%E8%A1%8C/</link>
      <pubDate>Thu, 25 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/java%E4%BC%A0%E9%80%92%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0%E6%87%92%E6%89%A7%E8%A1%8C/</guid>
      <description>看下面这个方法:
public static JSONObject call(byte[] img, String algName, String algUrl) { long startTime = System.currentTimeMillis(); try { HttpResponse resp = OkHttpUtil.post(algUrl, MediaType.parse(&amp;#34;application/octet-stream&amp;#34;), img, connectTimout, readAndWriteTimeout); // 省略代码块... } catch (Exception e) { // 省略代码块... } } 方法的入参是图片二进制流，模型名称和模型地址，方法的操作是用图片调用对应的模型，然后做一些日志记录、监控指标上报、错误处理等操作，最终返回模型的json格式结果。
可以看到其中模型的调用方式是确定的，直接将图片放在http body中，content-type为application/octet-stream
现在有一个模型，调用方式不一样，需要以form-data的格式把数据传过去，图片的名字必须为image, 像这样:
OkHttpUtil.post(url, null, &amp;#34;image&amp;#34;, img, null, 10000L, 10000L) 两者唯一的区别只是调用方式不一样，如果能把调用方式抽象出来单独传递的话，那是极好的。像Python这类的动态语言是很容易实现的，直接将函数作为参数传递，之后用()调用运算符调用即可：
def func(): return &amp;#34;world&amp;#34; def outter(fun): print(&amp;#34;hello, {}&amp;#34;.format(fun())) outter(func) # &amp;#34;hello, world&amp;#34; 联想到Java中是否也可以这样呢，Java也是可以支持函数式编程的，自然也是可以的。实现方式如下
定义一个函数式接口:
@FunctionalInterface public interface Lazy&amp;lt;T&amp;gt; { T value(); } 增加一个重载call方法，需要额外传入Lazy类型的参数httpHolder</description>
    </item>
    
    <item>
      <title>博客再开张</title>
      <link>https://ikebo.cc/post/migrate/%E5%8D%9A%E5%AE%A2%E5%86%8D%E5%BC%80%E5%BC%A0/</link>
      <pubDate>Mon, 22 Mar 2021 10:35:20 +0800</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/%E5%8D%9A%E5%AE%A2%E5%86%8D%E5%BC%80%E5%BC%A0/</guid>
      <description>最开始写博客应该是大一下学期左右就开始了，当时是在CSDN上写，主要记录一些平时学习和开发时遇到的一些问题和解决方式的经验文章，也有一部分是算法题的题解。这是我CSDN主页地址，截止目前已经有10w+的访问量了。
后来觉得有自己的独立博客更酷一些，也整过hexo这类的博客引擎，觉得限制较多，部署繁琐，觉得从头到尾自己设计开发一个博客更拽，当时就真的开始从头写博客网站，数据库设计、后端接口、前端样式、简单的评论功能、后台管理，后台新建文章的页面样式都自己在大学宿舍里一点点地写，印象比较深刻的有两个地方，一个是实现了文章发布之后保存为静态文件，之后再访问时直接托管到nginx，请求不用到达后端。另一个是markdown解析器和代码高亮的调研，当时调研了好多的markdown解析，最终终于找到了自己满意的markdown-it，还实现了例如自定义图片大小和图片浮动方向的语法和对应的样式。之前那个博客的域名已经迁移到这里了，目前可访问的地址是https://123.206.178.92，之后会将那个博客的文章陆续迁移到这里来。
时间久了之后，发现维护起来比较麻烦，而且技术含量不高，就想选一个比较方便管理、扩展的博客系统，偶然的机会发现了typecho，发现挺不错，整个框架很轻，主题和插件修改起来也方便，而且是开源的，可以自己随便写一些扩展或者做一些修改。然后又找到了handsome 这款typecho主题，这是一款功能丰富、做的很用心的主题，虽然是收费的，但是没关系。后面会基于这个主题做一些样式上的设置和定制。
写博客是个好习惯，博客的本质是记录，记录自己的成长，记录自己的心得体会、对生活的感悟。写博客时就像跟自己对话，这种感觉有些微妙。
我的博客又开张了，希望自己坚持写下去。</description>
    </item>
    
    <item>
      <title>Unix中的信号是怎么工作的</title>
      <link>https://ikebo.cc/post/migrate/part2/unix%E4%B8%AD%E7%9A%84%E4%BF%A1%E5%8F%B7%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84/</link>
      <pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/unix%E4%B8%AD%E7%9A%84%E4%BF%A1%E5%8F%B7%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84/</guid>
      <description>信号的作用 信号是一种异步通知机制，用来告知进程一个事件已经发生
信号的产生 信号可以由用户调用kill命令发送，也可以由操作系统在某些事件发生时产生，如计时器到期、子进程结束、访问了不改访问的内存等。
信号的工作过程1 当一个信号发送给某个进程时，内核会查看该进程的PCB以决定改信号的处理方式，如果该信号的处理动作是SIG_IGN，则会忽略改信号，如果处理动作是SIG_DFL，则内核会找到该信号的默认处理程序地址并执行。 如果该进程定义了该信号的处理程序，则会执行该程序。
如果进程注册了信号处理程序，则会在进程的待处理信号表中添加一项。当进程下次被调度执行时，内核会首先往该进程的堆栈空间添加一些数据，然后改变执行指令的地址(相当于改变8086架构CPU的CS和IP寄存器的值)，就像进程自己调用了信号处理程序一样。
当信号处理程序结束时，会继续执行之前的代码。
内核通常需要知道信号处理程序何时返回，比如当信号处理函数执行时，需要阻止相当的信号被再次传递，或者当信号处理函数执行完后，需要重新调用被信号中断的系统调用。要做到这一点，还需要改变堆栈和指令指针。
内核怎么知道进程的信号处理程序结束了2 内核往进程中映射了一页内存，改内存中有一个用来通知内核处理程序已完成的系统调用，然后将信号处理程序的返回地址改为该内存页的地址(就是改变栈顶的值)。
how-do-unix-signals-work&amp;#160;&amp;#x21a9;&amp;#xfe0e;
how-signals-work-internally&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>aiohttp ClientSession 用法踩坑</title>
      <link>https://ikebo.cc/post/migrate/part2/aiohttp-clientsession-%E7%94%A8%E6%B3%95%E8%B8%A9%E5%9D%91/</link>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/aiohttp-clientsession-%E7%94%A8%E6%B3%95%E8%B8%A9%E5%9D%91/</guid>
      <description>一般是这么用的：
async with aiohttp.ClientSession() as ses: res = await ses.post(xxx) text = await res.text() xxx 没有问题
但是为了减少缩进，可能想这样封装一下：
class HTTP: @staticmethod async def post(*args, **kwargs): async with aiohttp.ClientSession() as ses: return await ses.post(*args, **kwargs) 这是有问题的，with 上下文之后会关闭session的连接和资源，如果payload比较大，在连接关闭之后还没读完的话，可能会卡在await ses.text()那里，导致超时
所以需要在上下文关闭之前就把内容读取完毕并返回。
可以这样：
class HTTP: @staticmethod async def post(*args, **kwargs): async with aiohttp.ClientSession() as ses: async with await ses.post(*args, **kwargs) as res: return res, await res.text() 或者这样：
class HTTP: @classmethod async def get(cls, *args, **kargs): await cls.</description>
    </item>
    
    <item>
      <title>问题记录：Python 协程相关</title>
      <link>https://ikebo.cc/post/migrate/part2/%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95python-%E5%8D%8F%E7%A8%8B%E7%9B%B8%E5%85%B3/</link>
      <pubDate>Thu, 14 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95python-%E5%8D%8F%E7%A8%8B%E7%9B%B8%E5%85%B3/</guid>
      <description>import asyncio import multiprocessing q = multiprocessing.Queue(10000) for i in range(100): q.put(i) async def coro(i): print(&amp;#39;coro... {}&amp;#39;.format(i)) async def device_video_main(j): loop = asyncio.get_event_loop() for i in range(5): asyncio.ensure_future(coro(j), loop=loop) # await asyncio.sleep(1) async def run_integrate(): while True: j = q.get() print(&amp;#39;j: &amp;#39;, j) if True: loop = asyncio.get_event_loop() coro = device_video_main(j) loop.create_task(coro) # asyncio.ensure_future(coro, loop=loop) # await asyncio.sleep(1) # print(loop.is_running()) # async def main(): # loop = asyncio.get_event_loop() # for i in range(3): # asyncio.</description>
    </item>
    
    <item>
      <title>asyncio.sleep 和 time.sleep 的区别</title>
      <link>https://ikebo.cc/post/migrate/part2/asyncio.sleep-%E5%92%8C-time.sleep-%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Sun, 10 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/asyncio.sleep-%E5%92%8C-time.sleep-%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
      <description>time.sleep是针对整个线程，整个线程会挂起，不再执行任何操作。
asyncio.sleep是针对当前协程而言，告诉事件循环：请去执行别的操作，相当于模拟了一次网络IO，不会阻塞其他协程的执行。
import time import asyncio async def hello(): print(&amp;#39;Hello ...&amp;#39;) await asyncio.sleep(5) # time.sleep(5) print(&amp;#39;... World!&amp;#39;) async def main(): await asyncio.gather(hello(), hello()) loop = asyncio.get_event_loop() loop.run_until_complete(main()) 运行结果：
Hello ... Hello ... ... World! ... World! import time import asyncio async def hello(): print(&amp;#39;Hello ...&amp;#39;) # await asyncio.sleep(5) time.sleep(5) print(&amp;#39;... World!&amp;#39;) async def main(): await asyncio.gather(hello(), hello()) loop = asyncio.get_event_loop() loop.run_until_complete(main()) 运行结果：
Hello ... ... World! Hello ... ... World! </description>
    </item>
    
    <item>
      <title>SQLAlchemy中常见的query filter</title>
      <link>https://ikebo.cc/post/migrate/part2/sqlalchemy%E4%B8%AD%E5%B8%B8%E8%A7%81%E7%9A%84query-filter/</link>
      <pubDate>Sun, 08 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/sqlalchemy%E4%B8%AD%E5%B8%B8%E8%A7%81%E7%9A%84query-filter/</guid>
      <description>equals query.filter(User.name == &amp;#39;leela&amp;#39;) not equals: query.filter(User.name != &amp;#39;leela&amp;#39;) LIKE query.filter(User.name.like(&amp;#39;%leela%&amp;#39;)) IN query.filter(User.name.in_([&amp;#39;leela&amp;#39;, &amp;#39;akshay&amp;#39;, &amp;#39;santanu&amp;#39;])) # works with query objects too: query.filter(User.name.in_(session.query(User.name).filter(User.name.like(&amp;#39;%santanu%&amp;#39;)))) NOT IN query.filter(~User.name.in_([&amp;#39;lee&amp;#39;, &amp;#39;sonal&amp;#39;, &amp;#39;akshay&amp;#39;])) IS NULL filter(User.name == None) IS NOT NULL filter(User.name != None) AND from sqlalchemy import and_ filter(and_(User.name == &amp;#39;leela&amp;#39;, User.fullname == &amp;#39;leela dharan&amp;#39;)) #or, default without and_ method comma separated list of conditions are AND filter(User.name == &amp;#39;leela&amp;#39;, User.fullname == &amp;#39;leela dharan&amp;#39;) # or call filter()/filter_by() multiple times filter(User.</description>
    </item>
    
    <item>
      <title>Python 在CSV文件中写入中文字符</title>
      <link>https://ikebo.cc/post/migrate/part2/python-%E5%9C%A8csv%E6%96%87%E4%BB%B6%E4%B8%AD%E5%86%99%E5%85%A5%E4%B8%AD%E6%96%87%E5%AD%97%E7%AC%A6/</link>
      <pubDate>Wed, 25 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/python-%E5%9C%A8csv%E6%96%87%E4%BB%B6%E4%B8%AD%E5%86%99%E5%85%A5%E4%B8%AD%E6%96%87%E5%AD%97%E7%AC%A6/</guid>
      <description>对于UTF-8编码，Excel要求BOM(字节顺序标记)写在文件的开始，否则它会假设这是ANSI编码，这个就是与locale有依赖性了。
Python2
#!python2 #coding:utf8 import csv data = [[u&amp;#39;American&amp;#39;,u&amp;#39;美国人&amp;#39;], [u&amp;#39;Chinese&amp;#39;,u&amp;#39;中国人&amp;#39;]] with open(&amp;#39;results.csv&amp;#39;,&amp;#39;wb&amp;#39;) as f: f.write(u&amp;#39;\ufeff&amp;#39;.encode(&amp;#39;utf8&amp;#39;)) w = csv.writer(f) for row in data: w.writerow([item.encode(&amp;#39;utf8&amp;#39;) for item in row]) Python3
#!python3 #coding:utf8 import csv data = [[u&amp;#39;American&amp;#39;,u&amp;#39;美国人&amp;#39;], [u&amp;#39;Chinese&amp;#39;,u&amp;#39;中国人&amp;#39;]] with open(&amp;#39;results.csv&amp;#39;,&amp;#39;w&amp;#39;,newline=&amp;#39;&amp;#39;,encoding=&amp;#39;utf-8-sig&amp;#39;) as f: w = csv.writer(f) w.writerows(data) unicodecsv
#!python2 #coding:utf8 import unicodecsv data = [[u&amp;#39;American&amp;#39;,u&amp;#39;美国人&amp;#39;], [u&amp;#39;Chinese&amp;#39;,u&amp;#39;中国人&amp;#39;]] with open(&amp;#39;results.csv&amp;#39;,&amp;#39;wb&amp;#39;) as f: w = unicodecsv.writer(f,encoding=&amp;#39;utf-8-sig&amp;#39;) w.writerows(data) 转载自简书</description>
    </item>
    
    <item>
      <title>Python 获取线程中的异常信息</title>
      <link>https://ikebo.cc/post/migrate/part2/python-%E8%8E%B7%E5%8F%96%E7%BA%BF%E7%A8%8B%E4%B8%AD%E7%9A%84%E5%BC%82%E5%B8%B8%E4%BF%A1%E6%81%AF/</link>
      <pubDate>Thu, 12 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/python-%E8%8E%B7%E5%8F%96%E7%BA%BF%E7%A8%8B%E4%B8%AD%E7%9A%84%E5%BC%82%E5%B8%B8%E4%BF%A1%E6%81%AF/</guid>
      <description>通常情况下我们无法将多线程中的异常带回主线程，所以也就无法打印线程中的异常，而通过traceback模块，我们可以对线程做如下修改，从而实现捕获线程异常的目的1。
import threading import traceback def my_func(): raise BaseException(&amp;#34;thread exception&amp;#34;) class ExceptionThread(threading.Thread): def __init__(self, group=None, target=None, name=None, args=(), kwargs=None, verbose=None): &amp;#34;&amp;#34;&amp;#34; Redirect exceptions of thread to an exception handler. &amp;#34;&amp;#34;&amp;#34; threading.Thread.__init__(self, group, target, name, args, kwargs, verbose) if kwargs is None: kwargs = {} self._target = target self._args = args self._kwargs = kwargs self._exc = None def run(self): try: if self._target: self._target() except BaseException as e: import sys self._exc = sys.</description>
    </item>
    
    <item>
      <title>Python 限制函数运行时间</title>
      <link>https://ikebo.cc/post/migrate/part2/python-%E9%99%90%E5%88%B6%E5%87%BD%E6%95%B0%E8%BF%90%E8%A1%8C%E6%97%B6%E9%97%B4/</link>
      <pubDate>Wed, 11 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/python-%E9%99%90%E5%88%B6%E5%87%BD%E6%95%B0%E8%BF%90%E8%A1%8C%E6%97%B6%E9%97%B4/</guid>
      <description>实际项目中会涉及到需要对有些函数的响应时间做一些限制，如果超时就退出函数的执行，停止等待。
使用signal 使用signal有所限制，需要在linux系统上，并且需要在主线程中使用。方法二使用线程计时，不受此限制。
# coding=utf-8 import signal import time def set_timeout(num, callback): def wrap(func): def handle(signum, frame): # 收到信号 SIGALRM 后的回调函数，第一个参数是信号的数字，第二个参数是the interrupted stack frame. raise RuntimeError def to_do(*args, **kwargs): try: signal.signal(signal.SIGALRM, handle) # 设置信号和回调函数 signal.alarm(num) # 设置 num 秒的闹钟 print(&amp;#39;start alarm signal.&amp;#39;) r = func(*args, **kwargs) print(&amp;#39;close alarm signal.&amp;#39;) signal.alarm(0) # 关闭闹钟 return r except RuntimeError as e: callback() return to_do return wrap def after_timeout(): # 超时后的处理函数 print(&amp;#34;Time out!&amp;#34;) @set_timeout(2, after_timeout) # 限时 2 秒超时 def connect(): # 要执行的函数 time.</description>
    </item>
    
    <item>
      <title>Python中的operator模块</title>
      <link>https://ikebo.cc/post/migrate/part2/python%E4%B8%AD%E7%9A%84operator%E6%A8%A1%E5%9D%97/</link>
      <pubDate>Mon, 09 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/python%E4%B8%AD%E7%9A%84operator%E6%A8%A1%E5%9D%97/</guid>
      <description>operator 模块提供了一套与Python的内置运算符对应的高效率函数。例如，operator.add(x, y) 与表达式 x+y 相同。 许多函数名与特殊方法名相同，只是没有双下划线。为了向后兼容性，也保留了许多包含双下划线的函数。为了表述清楚，建议使用没有双下划线的函数。
operator.attrgetter
def attrgetter(*items): if any(not isinstance(item, str) for item in items): raise TypeError(&amp;#39;attribute name must be a string&amp;#39;) if len(items) == 1: attr = items[0] def g(obj): return resolve_attr(obj, attr) else: def g(obj): return tuple(resolve_attr(obj, attr) for attr in items) return g def resolve_attr(obj, attr): for name in attr.split(&amp;#34;.&amp;#34;): obj = getattr(obj, name) return obj operator.itemgetter
def itemgetter(*items): if len(items) == 1: item = items[0] def g(obj): return obj[item] else: def g(obj): return tuple(obj[item] for item in items) return g examples</description>
    </item>
    
    <item>
      <title>一键搭建ssr服务器并开启bbr加速</title>
      <link>https://ikebo.cc/post/migrate/part2/%E4%B8%80%E9%94%AE%E6%90%AD%E5%BB%BAssr%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%B9%B6%E5%BC%80%E5%90%AFbbr%E5%8A%A0%E9%80%9F/</link>
      <pubDate>Tue, 13 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E4%B8%80%E9%94%AE%E6%90%AD%E5%BB%BAssr%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%B9%B6%E5%BC%80%E5%90%AFbbr%E5%8A%A0%E9%80%9F/</guid>
      <description>一键搭建shadowsocksR
1 下载ssr搭建脚本
git clone -b master https://github.com/flyzy2005/ss-fly 2 运行ssr搭建脚本
ss-fly/ss-fly.sh -ssr 3 输入对应参数
4 相关命令
启动：/etc/init.d/shadowsocks start 停止：/etc/init.d/shadowsocks stop 重启：/etc/init.d/shadowsocks restart 状态：/etc/init.d/shadowsocks status 配置文件路径：/etc/shadowsocks.json 日志文件路径：/var/log/shadowsocks.log 代码安装目录：/local/shadowsocks 5 卸载ssr服务
./shadowsocksR.sh uninstall 一键开启bbr加速 ss-fly/ss-fly.sh -bbr 重启，输入以下命令查看是否成功开启bbr
sysctl net.ipv4.tcp_available_congestion_control 如果返回值为：
net.ipv4.tcp_available_congestion_control = bbr cubic reno 则说明开启成功
转载自这里</description>
    </item>
    
    <item>
      <title>git 放弃本地修改</title>
      <link>https://ikebo.cc/post/migrate/part2/git-%E6%94%BE%E5%BC%83%E6%9C%AC%E5%9C%B0%E4%BF%AE%E6%94%B9/</link>
      <pubDate>Fri, 09 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/git-%E6%94%BE%E5%BC%83%E6%9C%AC%E5%9C%B0%E4%BF%AE%E6%94%B9/</guid>
      <description>Look1:
git checkout . #本地所有修改的。没有的提交的，都返回到原来的状态 git stash #把所有没有提交的修改暂存到stash里面。可用git stash pop回复。 git reset --hard HASH #返回到某个节点，不保留修改。 git reset --soft HASH #返回到某个节点。保留修改 git reset HEAD^ #撤销上一次commit，回到没有add的状态 git clean -df #返回到某个节点 git clean 参数 -n 显示 将要 删除的 文件 和 目录 -f 删除 文件 -df 删除 文件 和 目录 也可以使用：
git checkout . &amp;amp;&amp;amp; git clean -xdf CSDN&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>为什么使用object.__setattr__</title>
      <link>https://ikebo.cc/post/migrate/part2/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8object.__setattr__/</link>
      <pubDate>Tue, 23 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8object.__setattr__/</guid>
      <description>werkzeug 0.6.1中Local的初始化是这样的：
class Local(object): __slots__ = (&amp;#39;__storage__&amp;#39;, &amp;#39;__lock__&amp;#39;) def __init__(self): object.__setattr__(self, &amp;#39;__storage__&amp;#39;, {}) object.__setattr__(self, &amp;#39;__lock__&amp;#39;, allocate_lock()) 我当时很奇怪为什么要用object.__setattr__, 而不是直接用self.__storage__, 当我直接用self.__storage__ = {}实现的时候才发现问题：
self.__storage__会调用__setattr__，而__setattr__中会调用self.__lock__.acquire()，因为此时self.__lock__还没有定义, 所以会调用self.__getattr__，而self.__getattr__中也会调用self.__lock__.acquire(), 此后就会一直调用self.__getattr__，最终导致StackOverflow。
而显示调用object.__setattr__就不会触发Local内部的__setattr__，从而避免上述情况。而且两者的效果是一样的，object.__setattr__的第一个参数是self，也就是这个实例，所以并不用担心是不是在父类定义了一个公共属性。
类似的还有使用object.__getattribute__的情况，一般也是为了避免无限递归。</description>
    </item>
    
    <item>
      <title>理解werkzeug中的Local对象</title>
      <link>https://ikebo.cc/post/migrate/part2/%E7%90%86%E8%A7%A3werkzeug%E4%B8%AD%E7%9A%84local%E5%AF%B9%E8%B1%A1/</link>
      <pubDate>Thu, 18 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/%E7%90%86%E8%A7%A3werkzeug%E4%B8%AD%E7%9A%84local%E5%AF%B9%E8%B1%A1/</guid>
      <description>ThreadLocal是线程级别的local，如果在greenlet或者协程这种微线程环境下，或者在多个请求共用一个线程的情况下，线程级别是不够的。ThreadLocal是thread-safe和thread-specific的, 而有些情况需要greenlet-safe和greenlet-specific或者request-safe和request-specific。
werkzeug 0.1版中Local的实现是这样的：
try: from py.magic import greenlet get_current_greenlet = greenlet.getcurrent del greenlet except (RuntimeError, ImportError): get_current_greenlet = lambda: None try: from thread import get_ident as get_current_thread from threading import Lock except ImportError: from dummy_thread import get_ident as get_current_thread from dummy_threading import Lock from werkzeug.utils import ClosingIterator def get_ident(): &amp;#34;&amp;#34;&amp;#34; Return a unique number for the current greenlet in the current thread. &amp;#34;&amp;#34;&amp;#34; return hash((get_current_thread(), get_current_greenlet())) class Local(object): def __init__(self): self.</description>
    </item>
    
    <item>
      <title>ThreadLocal</title>
      <link>https://ikebo.cc/post/migrate/part2/threadlocal/</link>
      <pubDate>Wed, 17 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/threadlocal/</guid>
      <description>TheadLocal 用于多线程环境下，线程之间可以使用相同的变量，而这个变量只与当前线程环境有关。werkzeug中有类似的实现，使每个路由处理函数都可使用相同的request变量，而这个对象的内容只与当前请求有关。
例如:1
import threading # 创建全局ThreadLocal对象: local_school = threading.local() def process_student(): # 获取当前线程关联的student: std = local_school.student print(&amp;#39;Hello, %s (in %s)&amp;#39; % (std, threading.current_thread().name)) def process_thread(name): # 绑定ThreadLocal的student: local_school.student = name process_student() t1 = threading.Thread(target= process_thread, args=(&amp;#39;Alice&amp;#39;,), name=&amp;#39;Thread-A&amp;#39;) t2 = threading.Thread(target= process_thread, args=(&amp;#39;Bob&amp;#39;,), name=&amp;#39;Thread-B&amp;#39;) t1.start() t2.start() t1.join() t2.join() 执行结果：
Hello, Alice (in Thread-A) Hello, Bob (in Thread-B) 廖雪峰的官方网站&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>git 切换 tag</title>
      <link>https://ikebo.cc/post/migrate/part2/git-%E5%88%87%E6%8D%A2-tag/</link>
      <pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/git-%E5%88%87%E6%8D%A2-tag/</guid>
      <description>有一种源码学习的方法是这样的：从最初的版本开始看，有的很大的开源项目最初可能就只有几百行。我们可以先把项目clone到本地，然后切换到最初般。
列出所有版本:
git tag 若一个tag都没有，则可能是因为你先fork了这个项目，然后本地再pull下来的，这种情况得先执行:
git fetch 然后，切换到指定版本：
git checkout tagname 切回到主分支：
git checkout master </description>
    </item>
    
    <item>
      <title>Python中的async/await</title>
      <link>https://ikebo.cc/post/migrate/python%E4%B8%AD%E7%9A%84async%E5%92%8Cawait/</link>
      <pubDate>Tue, 09 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/python%E4%B8%AD%E7%9A%84async%E5%92%8Cawait/</guid>
      <description>async/await是实现异步IO的语法糖，是Python3.7新出的关键字。async def可创建协程，而await可用来等待一个可等待对象的执行完成。这大大简化了协程的创建(在Python2中创建协程需要yield和send协同操作)
下面这个例子很简洁的说明了什么是异步IO1：
import asyncio async def count(): print(&amp;#34;One&amp;#34;) await asyncio.sleep(1) print(&amp;#34;Two&amp;#34;) async def main(): await asyncio.gather(count(), count(), count()) if __name__ == &amp;#34;__main__&amp;#34;: import time s = time.perf_counter() asyncio.run(main()) elapsed = time.perf_counter() - s print(f&amp;#34;{__file__} executed in {elapsed:0.2f} seconds.&amp;#34;) 运行结果：
$ python3 countasync.py One One One Two Two Two countasync.py executed in 1.01 seconds. gather会等待所有协程都返回后再返回一个结果列表，as_completed会当协程返回后立即返回：
&amp;gt;&amp;gt;&amp;gt; import asyncio &amp;gt;&amp;gt;&amp;gt; async def coro(seq) -&amp;gt; list: ... &amp;#34;&amp;#34;&amp;#34;&amp;#39;IO&amp;#39; wait time is proportional to the max element.</description>
    </item>
    
    <item>
      <title>crontab 记录</title>
      <link>https://ikebo.cc/post/migrate/part2/crontab-%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Fri, 05 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/crontab-%E8%AE%B0%E5%BD%95/</guid>
      <description>crontab 时间说明
# .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR #sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * command to be executed minute：代表一小时内的第几分，范围 0-59。 hour：代表一天中的第几小时，范围 0-23。 mday：代表一个月中的第几天，范围 1-31。 month：代表一年中第几个月，范围 1-12。 wday：代表星期几，范围 0-7 (0及7都是星期天)。 who：要使用什么身份执行该指令，当您使用 crontab -e 时，不必加此字段。 command：所要执行的指令。</description>
    </item>
    
    <item>
      <title>mysql中的varchar</title>
      <link>https://ikebo.cc/post/migrate/part2/mysql%E4%B8%AD%E7%9A%84varchar/</link>
      <pubDate>Fri, 05 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/part2/mysql%E4%B8%AD%E7%9A%84varchar/</guid>
      <description>长度范围是0到65535
varchar(255) 和 varchar(256)的区别 长度超过255时，用2个字节存储列的实际长度，未超过时用一个字段</description>
    </item>
    
    <item>
      <title>Python 中的协程</title>
      <link>https://ikebo.cc/post/migrate/python-%E4%B8%AD%E7%9A%84%E5%8D%8F%E7%A8%8B/</link>
      <pubDate>Fri, 05 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/python-%E4%B8%AD%E7%9A%84%E5%8D%8F%E7%A8%8B/</guid>
      <description>Python 中的协程 函数也叫子程序，其调用过程一般为：Main中调用A，等待A结束后调用B，等待B结束后调用C&amp;hellip; 函数的调用一般是单入口。
相比于函数，协程可以有多个入口来暂停(切换到其他协程执行)和恢复协程的执行。另外，协程的调用不像函数调用需要主函数按照特定顺序依次调用子程序，协程之间是协作关系，可以来回切换。
相比于线程，他们都是通过切换达到协作的目的。线程是由操作系统调度来实现切换，而协程是语言级别的切换，开销更小。
Python中，可以用生成器中的yield实现协程（支持不完全）
协程实现生产者／消费者模型1 import time def consumer(): r = &amp;#39;&amp;#39; while True: n = yield r if not n: return print(&amp;#39;consuming {}&amp;#39;.format(n)) time.sleep(1) r = &amp;#39;200 OK&amp;#39; def produce(c): next(c) # 启动协程，Python2写法： c.next() n = 0 while n &amp;lt; 5: n = n + 1 print(&amp;#39;producing: {}&amp;#39;.format(n)) r = c.send(n) print(&amp;#39;consumer return: {}&amp;#39;.format(r)) c.close() # 关闭协程 c = consumer() produce(c) 运行结果：
producing: 1 consuming 1 consumer return: 200 OK producing: 2 consuming 2 consumer return: 200 OK producing: 3 consuming 3 consumer return: 200 OK producing: 4 consuming 4 consumer return: 200 OK producing: 5 consuming 5 consumer return: 200 OK 用连接协程的方式创建管道2 def producer(sentence, next_coroutine): tokens = sentence.</description>
    </item>
    
    <item>
      <title>Python包的__path__变量</title>
      <link>https://ikebo.cc/post/migrate/python%E5%8C%85%E7%9A%84__path__%E5%8F%98%E9%87%8F/</link>
      <pubDate>Fri, 05 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/python%E5%8C%85%E7%9A%84__path__%E5%8F%98%E9%87%8F/</guid>
      <description>在包的__init__.py中，__path__变量指定包的搜索路径。__path__[0]默认为空，Pycharm中会将__path__[0]改为项目的根目录，以便我们可以用绝对路径的方式导入模块。
当需要在运行时确定使用哪一套配置时，__path__可以派上用场。如：
env = os.environ.get(&amp;#39;ENV&amp;#39;,&amp;#39;dev&amp;#39;) __path__ = os.path.abspath(os.path.join(__path__[0], env)) </description>
    </item>
    
    <item>
      <title>随机种子</title>
      <link>https://ikebo.cc/post/migrate/%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90/</link>
      <pubDate>Fri, 05 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90/</guid>
      <description>随机种子（Random Seed）是计算机专业术语，一种以随机数作为对象的以真随机数（种子）为初始条件的随机数。一般计算机的随机数都是伪随机数，以一个真随机数（种子）作为初始条件，然后用一定的算法不停迭代产生随机数。1
也就是说，如果我们知道种子，既可以用相同的随机数生成器生成相同的随机数。如：
In [31]: random.seed(666) In [32]: random.randint(1,100) Out[32]: 59 In [33]: random.seed(666) In [34]: random.randint(1,100) Out[34]: 59 In [35]: random.randint(1,100) Out[35]: 56 百度百科&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>Python 中的迭代器和生成器</title>
      <link>https://ikebo.cc/post/migrate/python-%E4%B8%AD%E7%9A%84%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%92%8C%E7%94%9F%E6%88%90%E5%99%A8/</link>
      <pubDate>Thu, 04 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/python-%E4%B8%AD%E7%9A%84%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%92%8C%E7%94%9F%E6%88%90%E5%99%A8/</guid>
      <description>Python的迭代器和生成器属于比较难理解的内容，不常使用的话又容易忘记。最近在看一些代码的时候经常看到__iter__和yield，发现如果想深入理解的话并不简单。
迭代器 Python中，能够通过for&amp;hellip;in循环遍历的对象都是可迭代对象iterable objects, 如list, dict等。迭代器是指实现了迭代协议的对象, 可通过next()函数调用并返回下一个值，直到最后抛出StopIteration错误。可迭代对象不一定是迭代器，可通过iter()函数将可迭代对象变成迭代器。
如：
class yrange: def __init__(self, n): self.i = 0 self.n = n def __iter__(self): return self def next(self): if self.i &amp;lt; self.n: i = self.i self.i += 1 return i else: raise StopIteration() 运行结果：
&amp;gt;&amp;gt;&amp;gt; y = yrange(3) &amp;gt;&amp;gt;&amp;gt; y.next() 0 &amp;gt;&amp;gt;&amp;gt; y.next() 1 &amp;gt;&amp;gt;&amp;gt; y.next() 2 &amp;gt;&amp;gt;&amp;gt; y.next() Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 14, in next StopIteration 生成器 生成器简化了迭代器的创建。如：</description>
    </item>
    
    <item>
      <title>WSGI的理解</title>
      <link>https://ikebo.cc/post/migrate/wsgi%E7%9A%84%E7%90%86%E8%A7%A3/</link>
      <pubDate>Thu, 04 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/wsgi%E7%9A%84%E7%90%86%E8%A7%A3/</guid>
      <description>WSGI(Web Server Gateway Interface)是描述Python应用和服务器之间标准接口的协议。若应用开发者和服务器开发者都实现这个协议，则双方都只需要专注自己所需要开发的功能，而不用考虑应用／服务器兼容的问题。
目前WSGI协议已经得到广泛实现, WSGI应用/框架有flask, django等，WSGI服务器有uWSGI(其实现的uwsgi协议是传输协议，主要用于与反向代理的通信), gunicorn等。
WSGI在PEP333中发布，主要内容为1：
WSGI application are callable python objects (functions or classes with a call method that are passed two arguments: a WSGI environment as first argument and a function that starts the response. the application has to start a response using the function provided and return an iterable &amp;gt; where each yielded item means writing and flushing. The WSGI environment is like a CGI environment just with some additional keys that are either provided by the server or a middleware.</description>
    </item>
    
    <item>
      <title>epoll/kqueue 的理解</title>
      <link>https://ikebo.cc/post/migrate/epoll-%E5%92%8C-kqueue%E7%9A%84%E7%90%86%E8%A7%A3/</link>
      <pubDate>Wed, 03 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/epoll-%E5%92%8C-kqueue%E7%9A%84%E7%90%86%E8%A7%A3/</guid>
      <description>tornado以异步IO的方式提高性能，对于有多条长连接的情况比较适合，比如聊天室。同步／异步，阻塞／非阻塞这两对概念比较难理解。epoll/kqueue是Linux内核用于异步IO的机制。
阻塞：比如等快递，假设快递没到你啥也干不了，这时你还不如去睡觉，因为你知道快递员到时候会打电话叫你。这种因为等快递而啥也干不了的状态就是阻塞，好处就是你可以轻松地去睡觉。对应到操作系统就是阻塞的线程一直在等待，也就是说这个线程只能同时处理这一个IO流，如果想要同时处理多个流，要没多进程，要么多线程，但是两者的性能都不高。因为线程被阻塞所以并不在系统的调度队列中，所以资源消耗很少。
非阻塞忙轮询：这就相当于你每隔一段时间就跟打电话给快递员问他快递到了没。对应到操作系统中，这种方式同时处理多个IO流，但是比较消耗资源，因为做了很多无效的遍历。
while true { for i in stream[]; { if i has data read until unavailable } } 为了了解阻塞是如何进行的，我们来讨论缓冲区，以及内核缓冲区，最终把I/O事件解释清楚。缓冲区的引入是为了减少频繁I/O操作而引起频繁的系统调用，当你操作一个流时，更多的是以缓冲区为单位进行操作，这是相对于用户空间而言。对于内核来说，也需要缓冲区。 假设有一个管道，进程A为管道的写入方，Ｂ为管道的读出方。
假设一开始内核缓冲区是空的，B作为读出方，被阻塞着。然后首先A往管道写入，这时候内核缓冲区由空的状态变到非空状态，内&amp;gt; 核就会产生一个事件告诉Ｂ该醒来了，这个事件姑且称之为“缓冲区非空”。 但是“缓冲区非空”事件通知B后，B却还没有读出数据；且内核许诺了不能把写入管道中的数据丢掉这个时候，Ａ写入的数据会滞留&amp;gt; 在内核缓冲区中，如果内核也缓冲区满了，B仍未开始读数据，最终内核缓冲区会被填满，这个时候会产生一个I/O事件，告诉进程 A，你该等等（阻塞）了，我们把这个事件定义为“缓冲区满”。 假设后来Ｂ终于开始读数据了，于是内核的缓冲区空了出来，这时候内核会告诉A，内核缓冲区有空位了，你可以从长眠中醒来 了，继续写数据了，我们把这个事件叫做“缓冲区非满”。 也许事件Y1已经通知了A，但是A也没有数据写入了，而Ｂ继续读出数据，知道内核缓冲区空了。这个时候内核就告诉B，你需要阻塞了！，我们把这个时间定为“缓冲区空”。 这四个情形涵盖了四个I/O事件，缓冲区满，缓冲区空，缓冲区非空，缓冲区非满（说的内核缓冲区）。这四个I/O事件是进行阻塞同步的根本。 那有没有一种机制，既可以同时处理多个IO流，又可以避免忙轮询呢？epoll/kqueue就是干这个的。阻塞模式下，内核对于I/O事件的处理是阻塞或者唤醒，而非阻塞模式下则把I/O事件交给其他对象。
为了避免CPU空转，可以引进了一个代理（select）。这个代理可以同时观察许多流的I/O事件，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态中醒来，于是我们的程序就会轮询一遍所有的流。
while true { select(streams[]) for i in streams[] { if i has data read until unavailable } } 如果没有I/O事件产生，我们的程序就会阻塞在select处。但是依然有个问题，我们从select那里仅仅知道了，有I/O事件发生了，但却并不知道是那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。
但是使用select，我们有O(n)的无差别轮询复杂度，同时处理的流越多，每一次无差别轮询时间就越长。
epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll之会把哪个流发生了怎样的I/O事件通知我们。此时我们对这些流的操作都是有意义的。（复杂度降低到了O(k)，k为产生I/O事件的流的个数，也有认为O(1)）
while true { active_stream[] = epoll_wait(epollfd) for i in active_stream[] { read or write till unavailable } } 部分整合自: 知乎</description>
    </item>
    
    <item>
      <title>tmux简单记录</title>
      <link>https://ikebo.cc/post/migrate/tmux%E7%AE%80%E5%8D%95%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ikebo.cc/post/migrate/tmux%E7%AE%80%E5%8D%95%E8%AE%B0%E5%BD%95/</guid>
      <description>Session
新建session
tmux new -s sessionname 退出当前session
prefix + d 进入session
tmux at -t sessionname 关闭session
tmux kill-session -t sessionname 列出所有session
tmux ls Window 新建window
prefix + c 切换window:
prefix + p/n 列出所有window:
prefix + w 删除当前window:
prefix + &amp;amp; Pane 切分pane
prefix + &amp;#34;/% 切换pane:
prefix + o 删除当前pane:
prefix + x 重启pane:
prefix + : 输入 respawn-pane -k，然后 Enter
prefix 默认为ctrl + b, 可自定义</description>
    </item>
    
  </channel>
</rss>
